​

​ ​

# ​ AI and ML BootCamp Learning Journey


v8.0.0



0


​

​ ​

## **Table of Contents**


**Table of Contents​** **1**

**Introduction​** **3**

What is a Bootcamp?​ 3

AI and ML Boot Camp Learning Journey​ 4

Target Work Roles​ 5
1. AI Engineer​ 5
2. Machine Learning Engineer​ 5
3. Data Scientist​ 5
4. Deep Learning Specialist​ 5
5. NLP Engineer​ 5
6. Generative AI / Agentic AI Developer​ 5

Learning Objectives​ 6

Knowledge​ 6
Skills​ 6
Attitude​ 6

Pre-requisites​ 7

About the Journey​ 7

**Program 1: Software Process​** **8**
Module 1: Introduction to Software Engineering​ 8
Module 2: Software Configuration Management​ 10
**Program 2: Project Management and Agile​** **11**
Module 1: Project Management Fundamentals​ 11
Module 2: Agile & Scrum​ 13
**Program 3: Interpersonal Skills​** **15**
Module 1: Communication Skills​ 15
Module 2: Presentation Skills​ 17
**Program 4: Python Programming Language for AI/ML​** **21**
Module 1: Python Fundamentals and Programming Basics​ 21
Module 2: Data Structures, Collections, and Exception Handling​ 24
Module 3: Object-Oriented Programming in Python​ 27
Module 4: Data Analysis with Python​ 28
Module 5: Data Visualization with Python​ 31
**Program 5: From Data to AI​** **34**
Module 1: Introduction to Data Science​ 34
Module 2: Introduction to Databases Management​ 36
Module 3: Introduction to SQL​ 37
Module 4: Introduction to API Development​ 42
**Program 6: Machine Learning​** **45**


v8.0.0

1


​

​ ​


Module 1: Introduction to AI & Machine Learning​ 45
Module 2: Supervised Learning​ 48
Module 3: Unsupervised Learning​ 51
Module 4: Time Series Analysis​ 53
Module 5: Recommendation Systems​ 55
**Program 7: Deep Learning​** **58**
Module 1: Neural Networks​ 58
Module 2: Machine Learning Frameworks​ 60
Module 3: Machine Learning Tradeoffs​ 63
Module 4: Convolutional Neural Networks & Modern Vision (CNNs)​ 67
Module 5: Model Deployment & Optimization​ 69
**Program 8: Natural Language Processing (NLP)​** **73**
Module 1: Introduction to NLP using Python and Word Representation​ 73
Module 2: Sequence Models​ 75
Module 3: Foundations of Transformers and Sequence-to-Sequence Models in Machine Learning​ 77
**Program 9: Generative AI Techniques​** **79**
Module 1: Introduction to Generative AI and Text-based Techniques​ 79
Module 2: Large Language Models (LLMs) and Prompts Engineering​ 81
Module 4: Generative AI in Practice — Text, Image, & Audio​ 83
**Program 10: Introduction to Agentic AI Development​** **86**
Module 1: Foundations of Agentic AI​ 86
Module 2: Introduction to Dify AI Agentic Framework​ 90
Module 3: Introduction to n8n Agentic Framework​ 93
Module 4: LangChain — Foundations & Applications​ 96
Module 5: Tools & Memories in LangChain​ 97
Module 6: LangChain — Tools, Agents & RAG​ 99
**Program 11: Career Boost​** **101**
Module 1: C.V. writing​ 101
Module 2: Understanding Interviews​ 105
Module 3: Pre-Interview Preparations​ 107
Module 4: During & Post Interview​ 110


v8.0.0

2


​

​ ​

## **Introduction** What is a Bootcamp?

The bootcamp is an intensive online learning program designed to enhance the technical and business skills
of selected candidates. Following a meticulous selection process, including technical assessments and HR
interviews, the bootcamp adopts an agile working environment. Learners are organized into teams with
dedicated scrum masters for each sprint, fostering agility and self-organization to simulate modern tech
environments.
Weekly rotation of scrum masters ensures a diverse experience for all learners. A quality process, featuring
peer reviews, guarantees high-quality output, immersing participants in a work-environment simulation and
improving interpersonal skills, as illustrated in Figure 1.


**Figure 1. Pillars of Engagement and work-environment Simulation**


This comprehensive approach, facilitated by top-tier experts, positions the journey as a uniquely effective
experience. Continuous assessment, conducted through a precise scoring system based on market
standards, evaluates learners' technical prowess, productivity, endurance, attitude, proactivity,
problem-solving skills, quality, storytelling, and team harmony.
The entire journey, inclusive of efforts from learners, experts, coaches, and Sprints professionals, is
conducted online, aligning with the latest global professional standards
Figure 2 shows the elements that are monitored through 360 feedback from learners and experts.


v8.0.0

3


​

​ ​


**Figure 2. Scoring system elements**

### AI and ML Boot Camp Learning Journey


This journey is designed to transform learners into technically proficient AI professionals ready to innovate

across data-driven industries. It builds mastery in programming, data handling, and model development

while integrating AI ethics, responsible deployment, and problem-solving in real contexts. Starting with solid

software engineering foundations, learners advance through Python, data science, and machine learning

before progressing to deep learning, NLP, generative AI, and agentic architectures. Each stage reinforces

how intelligent systems perceive, learn, and act, empowering learners to build AI that is explainable, ethical,

and impactful. Through applied projects and real-world case studies, participants practice the end-to-end AI

workflow—from data preprocessing and model training to deployment and monitoring. Graduates emerge

as technically grounded, analytically minded AI engineers capable of designing scalable, autonomous, and

human-aligned systems that drive innovation and transform organizations.


v8.0.0

4


​

​ ​

### Target Work Roles

##### **1.​ AI Engineer**

Designs, builds, and deploys AI-powered applications that automate processes, analyze data, and enhance

decision-making through machine learning and deep learning models.

##### **2.​ Machine Learning Engineer**


Specializes in building, training, optimizing, and deploying predictive models using frameworks like

Scikit-learn, PyTorch, and TensorFlow for real-world performance.

##### **3.​ Data Scientist**


Extracts insights from structured and unstructured data using statistical analysis, visualization, and

predictive modeling to guide data-driven decisions.

##### **4.​ Deep Learning Specialist**


- Develops neural network architectures (CNNs, RNNs, Transformers) for advanced applications in computer

vision, NLP, and speech processing.

##### **5.​ NLP Engineer**


Builds text and language understanding systems, including chatbots, sentiment analysis, and

question-answering models using embeddings and transformer-based architectures.

##### **6.​ Generative AI / Agentic AI Developer**


Builds text and language understanding systems, including chatbots, sentiment analysis, and

question-answering models using embeddings and transformer-based architectures. For Agenic AI, he

designs autonomous agents using LangChain, Dify, and RAG architectures to enable reasoning, memory,

and decision-making capabilities across intelligent workflows.


v8.0.0

5


​

​ ​

### Learning Objectives
##### **By the end of this Journey, the learner will be able to**


**Knowledge**


➔​ Explain the foundations of software engineering, SDLC models, and design patterns.

➔​ Describe project management principles, Agile methodologies, and their relevance to AI delivery.

➔​ Understand Python’s role in AI, including OOP, data structures, and library ecosystems.

➔​ Analyze machine learning paradigms—supervised, unsupervised, and reinforcement learning.

➔​ Explain deep learning architectures such as CNNs, RNNs, and Transformers.

➔​ Describe natural language processing workflows and embedding techniques.

➔​ Understand generative AI mechanisms, including VAEs, LLMs, and diffusion models.

➔​ Explain how agentic AI integrates reasoning, memory, and retrieval for autonomous operations.

➔​ Evaluate ethical, social, and security implications of AI in production systems.


**Skills**

➔ ​ Design and develop scalable software and AI systems using modern development lifecycles.

➔ ​ Apply Python programming, data manipulation, and visualization for analytical problem-solving.

➔ ​ Implement machine learning and deep learning models using frameworks such as Scikit-learn, Keras,

and PyTorch.

➔ ​ Build, evaluate, and optimize NLP, computer vision, and generative AI solutions.

➔ ​ Manage projects using Agile and Scrum methodologies to deliver AI-driven outcomes efficiently.

➔ ​ Communicate complex technical ideas clearly through professional writing and presentation.

➔ ​ Integrate APIs, databases, and cloud tools to create deployable AI applications.

➔ ​ Use prompt engineering, RAG, and agentic AI frameworks to design autonomous systems.

➔ ​ Apply data ethics, privacy, and responsible AI principles in real-world scenarios.


**Attitude**


➔ ​ Demonstrate curiosity and openness toward emerging AI and software innovations.

➔ ​ Practice ethical responsibility and fairness in designing and deploying AI solutions.

➔ ​ Exhibit collaboration and empathy when working within cross-functional and multicultural teams.

➔ ​ Show resilience, adaptability, and a growth mindset in dynamic technological environments.

➔ ​ Commit to continuous learning and improvement across evolving AI ecosystems.


v8.0.0

6


​

​ ​

### Pre-requisites
##### **Required skills learners should have before starting the Journey**


➔ ​ A bachelor’s degree in computer science, computer engineering, mathematics, or a related field

➔ ​ Basic proficiency in programming, preferably in Python or a similar high-level language

➔ ​ Strong knowledge of statistics and probability

➔ ​ Strong knowledge of linear algebra and calculus

➔ ​ Strong analytical and problem-solving abilities

### About the Journey
##### **Workload, Tasks, Projects, Impact, and Language**


➔ ​ **Workload (Hrs):** 350+

➔ ​ **Tasks:** 20+

➔ ​ **Projects:** 6+

➔ ​ **Weeks:** 15

➔ ​ **Live Sessions:** 30+

➔ ​ **Workload (Hrs / Week):** 30+

➔ ​ **Impact:** Hiring

➔ ​ **Language:** Arabic with English Artifacts


v8.0.0



7


​

​ ​

## **Program 1: Software Process**

### Module 1: Introduction to Software Engineering


**Introduction**


This module introduces the essential foundations of software engineering—its purpose, principles, and
practices that guide the creation of reliable, maintainable, and efficient software systems. Learners will
explore the software development lifecycle, core design concepts, and the role of APIs and diagrams in
structuring and communicating software solutions. By integrating theory with practical visualization tools,
the module prepares learners to analyze software quality, design effective architectures, and understand
professional software engineering workflows.


**Learning Objectives**


By the end of this module, learners will be able to:

➔ ​ Define the principles, objectives, and roles within software engineering.
➔ ​ Describe the key characteristics and quality factors of software systems.
➔ ​ Explain each phase of the Software Development Lifecycle (SDLC) and its deliverables.
➔ ​ Analyze different SDLC models and design patterns to select appropriate approaches.
➔ ​ Apply software design principles to structure maintainable and scalable solutions.
➔ ​ Interpret software diagrams to visualize system components and data flow.
➔ ​ Understand API fundamentals and demonstrate how APIs support software integration.


**Content**


**Topics** **Learning Outcomes**



**Importance of**
**Software Engineering**


**Software**
**Characteristics**



➔ ​ Explain the role and significance of software engineering

in the development of reliable and efficient software
systems.
➔ ​ Describe software engineering objectives and principles

and how they guide the software development process.
➔ ​ Identify and outline the roles and responsibilities of

software engineers in various phases of the software
development lifecycle.


➔ ​ Identify and describe key traits of software, including its

functionality, usability, and maintainability.
➔ ​ Analyze and explain the factors that impact software

quality, such as code structure, testing, and user
requirements.



**Software** ➔ ​ Describe an overview of the Software Development


v8.0.0



8


​

​ ​



**Development**
**Lifecycle (SDLC)**



Life Cycle (SDLC) phases, outlining the purpose and
sequence of each phase.
➔ ​ Identify and explain the key activities and



deliverables associated with each SDLC phase.
➔ ​ Compare and contrast different SDLC models,

evaluating their strengths and weaknesses in various
software development contexts.


**Software Design** ➔ ​ Explain core software design principles and their

application in creating effective software solutions.
➔ ​ Analyze and differentiate between various design

patterns and architectural styles used in software
development.


**API** ➔ ​ Understand API concepts.
➔ ​ Understand the API design pattern.


**Software Diagrams** ➔ ​ Utilize software diagrams to effectively visualize and

communicate different aspects of software
development.
➔ ​ Create and interpret software diagrams,

demonstrating proficiency in using them to represent
system components and interactions.


v8.0.0



9


​

​ ​

### Module 2: Software Configuration Management


**Introduction**


This module builds practical mastery of Software Configuration Management (SCM) and modern Version
Control with Git. You’ll learn why SCM matters, its objectives, and how disciplined change control improves
quality and reliability across the lifecycle. Then, you’ll apply Git essentials—repositories, commits, branches,
merges—and collaborate via GitHub using pull requests, reviews, and issues. Finally, you’ll connect
workflows to continuous integration for fast, safe delivery.


**Learning Objectives**


By the end of this module, learners will be able to:

➔ ​ Define SCM and its objectives in software projects.
➔ ​ Explain how SCM improves quality, traceability, and reliability.
➔ ​ Demonstrate Git basics: init, clone, commit, branch, merge, revert.
➔ ​ Apply branching strategies (e.g., Git Flow, trunk-based) to real tasks.
➔ ​ Collaborate on GitHub using PRs, code reviews, and issues.
➔ ​ Integrate CI pipelines that validate PRs and enforce quality gates.


**Content**


**Topics** **Learning Outcomes**



**SW Configuration**
**Management (CM) &**
**Version Control**
**Systems (VCS)**



➔ ​ Describe the concept of Software Configuration

Management (SCM) and its role in the software
development process.
➔ ​ Identify and explain the objectives of SCM in

managing software changes and configurations.
➔ ​ Analyze the benefits of SCM in enhancing software



quality and maintaining reliability throughout the
development lifecycle.


**Git VCS** ➔ ​ Effectively use Git to track and manage software

changes throughout the development process.
➔ ​ Explain the basics of Git, including key commands



and concepts, to manage version control.
➔ ​ Utilize GitHub for collaboration and code



management, applying best practices for team-based
development.
➔ ​ Develop skills in branching, conducting code reviews,



tracking issues, and implementing continuous
integration using Git and GitHub.



v8.0.0



10


​

​ ​

## **Program 2: Project Management and Agile**

### Module 1: Project Management Fundamentals


**Introduction**


In this module, learners will delve into the essential principles and practices of project management,
focusing on the various stages of project execution from initiation to closure. The module aims to equip
learners with the knowledge and skills necessary to effectively plan, execute, monitor, and control projects
to achieve their objectives within scope, schedule, and budget constraints.


**Learning Objectives**


By the end of this module, learners will be able to:

➔ ​ Apply project management principles, methodologies, and best practices in managing software

development projects.
➔ ​ Identify and describe the stages of the project lifecycle and their significance in project management.
➔ ​ Develop proficiency in using project management tools to plan, execute, and monitor projects

effectively.
➔ ​ Explain the roles and responsibilities of a project manager in leading and coordinating project

activities.
➔ ​ Improve communication, collaboration, and leadership skills to effectively manage teams and

execute projects successfully.


**Content**


**Topics** **Learning Outcomes**



**Project & Product**
**Management**
**Collaboration**



➔ ​ Explain the role of project management in achieving



successful project outcomes.
➔ ​ Identify and describe the advantages of effective



project management, including improved efficiency,
risk management, and goal attainment.
➔ ​ Explain the role of product management in achieving



a company’s success.
➔ ​ Identify the difference between project and product



management


**Project Initiation** ➔ ​ Describe the project initiation phase and outline its



key goals and activities.
➔ ​ Identify and explain project selection criteria used to



evaluate and prioritize potential projects.
➔ ​ Develop proficiency in identifying and analyzing



stakeholders relevant to a project's success.



v8.0.0



11


​

​ ​


**Project Planning** ➔ ​ Explain the significance of project planning in

ensuring project success and meeting objectives.
➔ ​ Develop the ability to create key project planning

documents, including scope statements, Work
Breakdown Structures (WBS), schedules, budgets,
and resource plans.



**Project Execution** ➔ ​ Apply structured thinking to plan, execute, and



document projects effectively.
➔ ​ Demonstrate problem-solving and decision-making



skills in realistic project contexts.
➔ ​ Communicate and collaborate efficiently with



stakeholders to ensure project success.
➔ ​ Design and present project insights through clear,



well-structured slides and reports.
➔ ​ Evaluate learning progress and project outcomes

through reflection, quizzes, and documentation.



**Project Monitoring &**
**Control**


v8.0.0



➔ ​ Develop the ability to monitor project performance



using key metrics and indicators.
➔ ​ Explain project controls and change management



processes, including their importance in maintaining
project alignment and addressing deviations.
➔​ Effectively use project management tools to track



progress, manage changes, and ensure project
objectives are met.


➔​ Describe the objectives and activities involved in the

project closure phase.


➔​ Conduct thorough project reviews, assessing

outcomes against objectives.


➔​ Explain the significance of celebrating successes and

how it contributes to team morale and future project
motivation.



12


​

​ ​

### Module 2: Agile & Scrum


**Introduction**


In this module, learners will delve into the principles and practices of Agile and Scrum methodologies, which
have revolutionized project management in the software industry and beyond. Starting with an exploration
of why Agile methodologies are crucial in today's dynamic and rapidly evolving business environment, the
module progresses to provide a solid foundation in Agile concepts and principles. Learners will then dive
deeper into Agile and Scrum frameworks, understanding their roles, processes, and best practices. By the
end of this module, learners will have a comprehensive understanding of Agile and Scrum methodologies
and how to apply them effectively in project management contexts.


**Learning Objectives**



By the end of this module, learners will be able to:



➔ ​ Apply Agile and Scrum methodologies effectively in managing projects.
➔ ​ Demonstrate expertise in Agile principles, practices, and the Scrum framework through practical



application.
➔ ​ Explain how Agile methodologies benefit customers and stakeholders by improving project



responsiveness and outcomes.
➔ ​ Implement Agile and Scrum practices to enhance project flexibility and foster collaboration among

team members.
➔ ​ Improve communication, collaboration, and problem-solving skills within Agile teams to ensure

successful project delivery.


**Content**


**Topics** **Learning Outcomes**



**Agile Mindset**
**Foundations**


**Scrum Framework**
**Explained**


v8.0.0



➔ ​ Define Agile vs. Waterfall and when each is suitable.
➔ ​ Explain “incremental,” “timeboxed,” and Agile



approach fundamentals.
➔ ​ Interpret the Agile Manifesto’s 4 values and 12



principles.
➔ ​ Translate principles into practical team behaviors



and practices.
➔ ​ Assess team alignment with an Agile mindset.



➔ ​ Describe Scrum roles: Product Owner, Scrum Master,



Developers.
➔ ​ Create user stories with INVEST; define DoD and



story points.
➔ ​ Organize and prioritize a backlog using



MoSCoW/Kano; identify MVP.
➔ ​ Plan and run sprints: backlog, standups, review,



13


​

​ ​


retrospective.
➔ ​ Use information radiators and SHO-HA-RI to drive

improvement.


**Kanban and Lean** ➔ ​ Visualize workflow on a Kanban board with WIP

limits.
➔ ​ Apply pull systems to improve flow and reduce

bottlenecks.
➔ ​ Identify and eliminate waste using Lean principles.
➔ ​ Track lead time/cycle time to guide continuous

improvement.



**Scaled Agile**
**Frameworks**


**Common Pitfalls and**
**Best Practices**


v8.0.0



➔ ​ Differentiate Nexus, LeSS, Scrum@Scale, DAD, and

SAFe.
➔ ​ Select a scaling approach based on org size and

constraints.
➔ ​ Explain roles, synchronization events, and

dependency management.
➔ ​ Outline high-level planning (e.g., PI planning) for

multiple teams.


➔ ​ Spot Agile antipatterns and propose corrective

actions.
➔ ​ Clarify the purpose and risks of “Sprint Zero.”
➔ ​ Use lightweight modeling techniques to refine

solutions.
➔ ​ Facilitate collaboration games to align stakeholders.
➔ ​ Prioritize with WSJF to balance value, size, and

urgency.



14


​

​ ​

## **Program 3: Interpersonal Skills**

### Module 1: Communication Skills


**Introduction**


In this module, learners will explore the fundamental aspects of communication skills, which are essential
for effective interpersonal interactions in both personal and professional contexts. From understanding the
basics of communication to honing verbal, written, interpersonal, and team communication skills, this
module aims to equip learners with the knowledge and techniques needed to communicate confidently and
effectively in various situations.


**Learning Objective**


By the end of this module, learners will be able to:

➔ ​ Explain the significance of communication skills in professional and team settings.
➔ ​ Demonstrate proficiency in verbal, written, and interpersonal communication across various



contexts.
➔ ​ Improve listening skills, empathy, and the ability to interpret non-verbal cues to enhance overall



communication effectiveness.
➔ ​ Adapt communication styles to suit different audiences and situations, ensuring clarity and



understanding.
➔ ​ Apply effective conflict resolution and negotiation techniques to resolve disagreements and reach



consensus.
➔ ​ Strengthen collaboration and teamwork by utilizing strong communication and interpersonal skills.


**Content**


**Topic** **Learning Outcomes**



**Introduction to**
**Communication Skills**


**Verbal**
**Communication Skills**


v8.0.0



➔ ​ Explain the significance of communication skills in



both personal and professional contexts.
➔ ​ Identify and describe the key elements that



contribute to effective communication.
➔ ​ Analyze communication barriers and develop



strategies to overcome them for more effective
interactions.



➔ ​ Demonstrate advanced verbal communication skills

by effectively conveying ideas, opinions, and
emotions in various contexts.
➔ ​ Practice techniques for expressing ideas, opinions,

and emotions clearly and persuasively in verbal
interactions.



15


​

​ ​


➔ ​ Explain and apply active listening techniques to

improve comprehension and engagement in
conversations.



**Written**
**Communication Skills**


**Interpersonal**
**Communication Skills**


**Team Communication**
**Skills**


v8.0.0



➔ ​ Produce clear, concise, and professional written



communications tailored to various audiences and
purposes.
➔ ​ Structure emails effectively, ensuring clarity,



organization, and appropriate tone in written
communication.
➔ ​ Apply proper grammar, punctuation, and formatting



to enhance the readability and professionalism of
written documents.



➔ ​ Establish rapport, trust, and empathy in



interpersonal interactions by applying effective
communication techniques.
➔ ​ Develop skills to manage emotions and resolve



conflicts constructively in both personal and
professional settings.
➔ ​ Analyze and interpret non-verbal cues to enhance



communication and understanding in various
interactions.



➔ ​ Apply effective team communication strategies to

enhance collaboration and achieve shared goals.
➔ ​ Develop skills in facilitating discussions, leading

brainstorming sessions, and managing meetings to
ensure productive outcomes.
➔ ​ Explain the significance of clarity, transparency, and

accountability in team communication and
implement these principles in team interactions.



16


​

​ ​

### Module 2: Presentation Skills


**Introduction**


This module empowers learners to communicate with clarity, empathy, and impact in professional settings.
It explores each stage of the communication cycle—from sender, message, and channel to receiver and
feedback—while addressing barriers and personal styles using the DISC framework. Through practical
strategies and self-reflection, learners build the ability to tailor messages, choose the right channels,
manage feedback constructively, and adapt to diverse communication preferences to strengthen
collaboration and workplace relationships.


**Learning Objectives**


By the end of this module, learners will be able to:

➔ ​ Define key elements and stages of the communication cycle.
➔ ​ Describe the roles and responsibilities of sender and receiver.
➔ ​ Apply effective message structuring and assertive communication techniques.
➔ ​ Select appropriate communication channels to suit context and purpose.
➔ ​ Demonstrate active listening and feedback skills for clarity and trust.
➔ ​ Analyze common barriers and implement strategies to overcome them.
➔ ​ Adapt communication styles to different audiences using the DISC model.


**Content**


**Topic** **Learning Outcomes**



**How to communicate**
**effectively**



➔ ​ Define communication and explain the

communication cycle.
➔ ​ Identify why effective communication impacts results

and relationships.
➔ ​ Apply the cycle to simple workplace scenarios.
➔ ​ Self-assess strengths and gaps in your

communication approach.



**Sender** ➔ ​ Describe the sender’s role and responsibilities.
➔ ​ Craft clear, audience-aware messages with



persuasive intent.
➔ ​ Use Ethos, Pathos, Logos appropriately for influence.
➔ ​ Evaluate and refine your sender behavior before



delivery.



**Message** ➔ ​ Distinguish message content from tone and intent.
➔ ​ Ensure clarity with framing and simple structure.
➔ ​ Apply an Assertiveness Formula to express needs

respectfully.



v8.0.0



17


​

​ ​


➔ ​ Adapt wording to context while preserving core

intent.


**Channel** ➔ ​ Explain common channels and the basic

communication model.
➔ ​ Select the best channel using a channels pyramid.
➔ ​ Anticipate noise/constraints and mitigate channel

risks.
➔ ​ Match urgency and sensitivity to

synchronous/asynchronous choices.


**Receiver** ➔ ​ Define the receiver’s role in meaning-making.
➔ ​ Ask clarifying questions to reduce ambiguity.
➔ ​ Differentiate listening levels; move toward

active/empathic listening.
➔ ​ Demonstrate receiver behaviors that build trust and

accuracy.



**Feedback** ➔ ​ Explain what feedback is and why it matters.
➔ ​ Deliver constructive feedback using a simple



framework.
➔ ​ Receive feedback non-defensively and extract action



points
➔ ​ Close the loop with follow-up and measurable next



steps.



**Communication**
**Barriers**


**Communication Styles**
**(DISC)**


v8.0.0



➔ ​ Identify common barriers (linguistic, cultural,



emotional, channel).
➔ ​ Diagnose where barriers appear in the cycle.
➔ ​ Apply strategies to prevent, surface, and resolve



barriers.



➔ ​ Recognize D, I, S, C style preferences and cues.
➔ ​ Adapt messaging and pace to different styles.
➔ ​ Leverage team diversity by flexing your own style.
➔ ​ Summarize style impacts on conflict, collaboration,

and decisions.



18


​

​ ​


v8.0.0



19


​

​ ​


v8.0.0



20


​

​ ​

## **Program 4: Python Programming Language for AI/ML**

### Module 1: Python Fundamentals and Programming Basics


**Introduction**


This module introduces learners to the foundational concepts of Python programming, from understanding
its capabilities to writing functional and structured code. It covers Python syntax, data types, operators,
control flow, and functions—building the essential skills for writing efficient, reusable, and readable
programs. Through hands-on exercises, learners gain confidence in manipulating data structures, applying
operators, controlling program logic, and modularizing code with functions and recursion to solve real-world
programming challenges.


**Learning Objectives**


By the end of this module, learners will be able to:


➔ ​ **Describe** Python’s purpose, features, and its role in modern programming.


➔ ​ **Recognize** and **apply** correct Python syntax to write basic scripts.


➔ ​ **Identify** and **manipulate** core data types, lists, tuples, and sets.


➔ ​ **Explain** and **demonstrate** various operators and their precedence.​


➔ ​ **Implement** control flow structures (if, for, while) to guide program logic.​


➔ ​ **Define** and **use** functions, parameters, and return values effectively.​


➔ ​ **Create** recursive and lambda functions to solve specific computational problems.
##### **Content**


**Topic** **Learning Outcomes**



**Introduction to**
**Python**


v8.0.0



➔ ​ Introducing the Python capabilities and features.
➔ ​ Describe Python’s capabilities and significance in

programming.
➔ ​ Recognize and use Python syntax to write basic code.



21


​

​ ​


**Python Basics** ➔ ​ Explain Python basics and their significance in

programming.
➔ ​ Investigate and describe Python data types and data

structures.
➔ ​ Explore and utilize variables, lists, tuples, and sets in

Python.


**Operators in Python** ➔ ​ Describe the different types of operators in Python

and their uses.
➔ ​ Explain operator precedence and its effect on

expression evaluation.
➔ ​ Apply bitwise operators to perform operations on

binary data.


**Python Control Flow** ➔ ​ Explain the purpose and structure of conditional

statements in Python, including if, elif, and else, and
how they control program flow based on logical
conditions.
➔ ​ Implement nested and compound conditional

statements using logical operators (and, or, not) to
handle multiple decision paths effectively.
➔ ​ Differentiate between iterative structures—for and



while loops—and determine when to use each for
solving programming problems.
➔ ​ Apply loop control statements (break, continue, pass)



to manage iteration behavior efficiently within
programs.
➔ ​ Construct nested loops and integrate them with



conditional logic to solve complex computational and
data-processing tasks.
➔ ​ Design and debug Python programs that combine



conditions and loops to implement real-world
decision-making and repetitive operations effectively.


**Functions** ➔ ​ Explain the meaning and applications of functions in

Python.
➔ ​ Define and implement functions to perform specific

tasks.
➔ ​ Describe and utilize function parameters, including

default parameter values.
➔ ​ Understand and use return values to pass data from

functions.
➔ ​ Call functions effectively within Python programs.
➔ ​ Explain and apply variable scope within functions.



v8.0.0



22


​

​ ​


➔ ​ Explore and create lambda functions for concise

function definitions.
➔ ​ Practice and implement recursion to solve problems

in Python.


v8.0.0



23


​

​ ​

### Module 2: Data Structures, Collections, and Exception Handling

##### **Introduction**

Build practical Python skills across three pillars: data structures, robust error handling, and file I/O. You’ll
compare lists, tuples, sets, and dictionaries; analyze their performance; and implement solutions using core
and collections types—plus recursion where it fits. Then you’ll write resilient code with exceptions (raise,
catch, else, finally, custom errors). Finally, you’ll read and write text/binary files, manage paths, and perform
safe operations (copy/move/delete) using blocks. By the end, you’ll craft reliable programs that handle
real-world data—and failures—gracefully.
##### **Learning Objectives:**


By the end of this module, the learner will be able to:


➔ ​ Classify Python data structures by properties and use cases.


➔ ​ Analyze time/space trade-offs for structure selection.


➔ ​ Implement operations (traverse, search, mutate) using core and collections types.


➔ ​ Apply recursion with suitable data-structure problems.


➔ ​ Construct resilient flows using try/except/else/finally and custom exceptions.


➔ ​ Operate on files: open modes, paths, text/binary reads and writes, safe cleanup with with.

#### **Content**


**Topic** **Learning Outcomes**


**Data Structures** ➔ ​ Identify and describe Python’s list, tuple, set, and

dictionary data structures.
➔ ​ Compare their functionality and use cases to

determine the most suitable data structure for
different tasks.
➔ ​ Practice traversing and searching within data

structures.
➔ ​ Analyze time and space complexities to evaluate the

efficiency of data structures.
➔ ​ Implement and work with common data structures in

Python.
➔ ​ Apply recursion techniques with data structures.
➔ ​ Explore and use specialized data structures from the


v8.0.0

24


​

​ ​


Python collections module.
➔ ​ Work with file data structures to handle and

manipulate data from files.
➔ ​ Apply data structures to solve various programming

challenges.


**Exceptions Handling** ➔ ​ Explain what exceptions are and why they are used in

Python.
➔ ​ Identify and differentiate between various types of

exceptions, such as NameError, IndexError,
ValueError, KeyError, and user-defined
exceptions.
➔ ​ Raise exceptions to manage error conditions.
➔ ​ Handle exceptions using try and except blocks to

manage error scenarios.
➔ ​ Use the finally clause to ensure that cleanup code



runs regardless of whether an exception occurred.
➔ ​ Apply the else clause to execute code when no



exceptions are raised.
➔ ​ Handle multiple exception types within a single try



block.
➔ ​ Raise exceptions at appropriate levels in your code to



manage errors effectively.
➔ ​ Implement user-defined exceptions to address

specific error conditions in your application.



**File Handling** ➔ ​ Explain what files are and how Python interacts with

the filesystem.
➔ ​ Open files in various modes, including r (read), w



(write), a (append), and r+ (read and write).
➔ ​ Practice opening files using the open() function.
➔ ​ Read data from files effectively.
➔ ​ Write data to files and practice file writing

techniques.
➔ ​ Close files properly using the close() method.
➔ ​ Handle FileNotFound and Permission errors

using try and except.
➔ ​ Work with both relative and absolute file paths.
➔ ​ Use the with statement to ensure files are



automatically closed after operations.
➔ ​ Read and write both binary and text files.
➔ ​ Implement file operations such as copying, moving,

and deleting files.



v8.0.0



25


​

​ ​


➔ ​ Manage input and output data through file handling

in programs.


v8.0.0



26


​

​ ​

### Module 3: Object-Oriented Programming in Python

##### **Introduction**

This module introduces learners to the principles and practices of Object-Oriented Programming (OOP) in
Python. It begins with the fundamentals of defining classes and creating objects, then progresses to
advanced concepts like encapsulation, inheritance, and polymorphism. Learners will gain hands-on
experience modeling real-world systems using Python’s OOP features—constructors, method overriding,
and access modifiers—to write modular, reusable, and maintainable code that reflects strong software
design principles.
##### **Learning Objectives:**


By the end of this module, the learner will be able to:


➔ ​ Define and create Python classes with attributes and methods.


➔ ​ Apply constructor methods (__init__) to initialize object states.


➔ ​ Explain key OOP principles: encapsulation, abstraction, inheritance, and polymorphism.


➔ ​ Model real-world problems using classes and objects.


➔ ​ Implement inheritance and method overriding to promote code reuse.


➔ ​ Differentiate between access types (public, private, protected) and use class/static methods

appropriately.
##### **Content**


**Topic** **Learning Outcomes**


**Classes In Python** ➔ ​ Describe the basics of object-oriented programming

(OOP) in Python.
➔ ​ Define classes in Python with attributes (properties)

and methods (behaviors).
➔ ​ Use constructor methods (__init__) to initialize

object attributes when creating new instances.


**OOP in Python** ➔ ​ Explain the core concepts of object-oriented

programming (OOP), including encapsulation,
abstraction, inheritance, and polymorphism.
➔ ​ Model real-world entities as objects (instances of

classes) with properties (attributes) and behaviors
(methods).
➔ ​ Organize, reuse, and enhance the flexibility of Python


v8.0.0

27


​

​ ​


code through the use of classes and objects.
➔ ​ Implement advanced OOP techniques, such as

constructors, inheritance, method overriding, and
manage access with public, private, and protected
methods, as well as class and static methods.

### Module 4: Data Analysis with Python

##### **Introduction**


This module equips learners with essential data analysis skills using **NumPy** and **Pandas** . It starts with array
operations and matrix computations in NumPy, progressing to efficient data import, transformation, and
analysis using Pandas. Learners will master reshaping, filtering, grouping, merging, and time series
operations while applying vectorization and performance optimization. By combining both libraries, learners
develop the ability to handle real-world datasets, perform end-to-end data manipulation, and build a strong
foundation for advanced data science workflows.

##### **Learning Objectives**


By the end of this module, the learner will be able to:


➔​ Explain the purpose and advantages of NumPy for numerical computing.


➔​ Create and manipulate NumPy arrays for data storage and operations.


➔​ Apply linear algebra and vectorized computations for performance.


➔​ Construct and analyze Pandas Series and DataFrames from multiple data sources.


➔​ Manipulate and clean data using selection, aggregation, and reshaping techniques.


➔​ Integrate NumPy with Pandas for efficient feature engineering and analysis.


➔​ Evaluate dataset performance trade-offs and scalability using advanced Pandas techniques.
##### **Content**


**Topic** **Learning Outcomes**



**Introduction to**
**NumPy**


v8.0.0



➔ ​ Explain what NumPy is and why it’s fast.
➔ ​ Install/import NumPy and create simple arrays.
➔ ​ Use basic array properties (shape, dtype, ndim).
➔ ​ Perform first operations: slicing, broadcasting,



28


​

​ ​


arithmetic.


**NumPy Fundamentals** ➔ ​ Import data from CSV, text, and other files into

NumPy arrays.
➔ ​ Reshape arrays using various methods and

techniques.
➔ ​ Create arrays from lists, ranges, and files.
➔ ​ Manipulate arrays (reshape, concatenate, transpose).
➔ ​ Apply math ops and boolean indexing for filtering.
➔ ​ Control dtypes, casting, and random number

generation.



**Linear Algebra with**
**NumPy**



➔ ​ Perform matrix operations (dot, transpose, inverse

basics).
➔ ​ Use ufuncs for efficient element-wise computation.
➔ ​ Solve linear systems with numpy.linalg.solve.
➔ ​ Interpret results for real data problems.



**Advanced NumPy** ➔ ​ Reshape, stack, and split arrays like a pro.
➔ ​ Use advanced/conditional indexing patterns.
➔ ​ Apply in-place ops and vectorized transforms.
➔ ​ Optimize small pipelines with pure NumPy.



**Introduction to**
**Pandas**


**Data manipulation**
**with Pandas**



➔ ​ Define Series vs. DataFrame and when to use each.
➔ ​ Create DataFrames from dicts, lists, and files

(CSV/Excel).
➔ ​ Import data with parsing options (types, dates)
➔ ​ Explore datasets with head, info, describe.


➔ ​ Select data with labels/positions (.loc, .iloc).
➔ ​ Handle missing data (detect, fill, drop) responsibly.
➔ ​ Reshape with pivot/melt and tidy principles.
➔ ​ Validate shapes and indexes after transforms.



**Pandas for Analysis** ➔ ​ Group data and apply aggregations (groupby, agg).
➔ ​ Combine advanced aggregations and custom

functions.
➔ ​ Perform DataFrame operations (merge, join, concat).
➔ ​ Get started with time series: parse, set index,

resample.


**Advanced Pandas** ➔ ​ Write vectorized code for performance (avoid loops).


v8.0.0



29


​

​ ​


➔ ​ Mix NumPy + Pandas for feature engineering.
➔ ​ Build practical features (bins, lags, one-hots, ratios).
➔ ​ Compare Pandas vs. Polars trade-offs on speed/scale.


v8.0.0



30


​

​ ​

### Module 5: Data Visualization with Python

##### **Introduction**


This module empowers learners to transform raw data into meaningful insights through compelling
visualizations. Starting with visualization principles, learners progress from static chart creation with
**Matplotlib** and **Seaborn** to interactive dashboards using **Plotly** and **PygWalker** . They’ll explore 2D and 3D
plots, statistical summaries, geo-visualization, and storytelling through design best practices. By mastering
these libraries, learners will be able to communicate complex data clearly, design professional visuals, and
build engaging analytical dashboards directly within Jupyter environments.

##### **Learning Objectives**


By the end of this module, the learner will be able to:

➔​ Explain the importance of visualization in data storytelling and communication.


➔​ Apply design principles (clarity, context, accuracy) to create effective visuals.


➔​ Construct a variety of plots using Matplotlib and customize them for professional presentation.


➔​ Utilize Seaborn for statistical visualization and multivariate data exploration.


➔​ Develop interactive charts and dashboards using Plotly and Plotly Dash.


➔​ Create geo-visualizations integrating spatial and temporal data insights.


➔​ Leverage PygWalker for no-code, rapid visual analytics within Jupyter Notebooks.

##### **Content**


**Topic** **Learning Outcomes**



**Introduction to Data**
**Visualization**


**Matplotlib**
**Fundamentals**


v8.0.0



➔ ​ Explain the importance of visualization in



communicating data insights.
➔ ​ Apply key principles of effective design (clarity,

context, accuracy).
➔ ​ Distinguish between good and poor visual practices.
➔ ​ Identify the capabilities of Matplotlib, Seaborn, Plotly,

and PygWalker.
➔ ​ Select the right library for interactive or static visuals.


➔ ​ Install and import Matplotlib for basic plotting.
➔ ​ Create line, scatter, bar, and histogram plots.
➔ ​ Generate box and pie plots for categorical



31


​

​ ​


summaries.
➔ ​ Label, style, and interpret simple visual outputs.


**Matplotlib Advanced** ➔ ​ Customize plot aesthetics (colors, markers, titles,



**Seaborn Statistical**
**Visualization**



legends).
➔ ​ Build multi-plot layouts and subplots for

comparisons.
➔ ​ Annotate and highlight key data points.
➔ ​ Explore 3D plotting and save figures for reports.
➔ ​ Apply best practices for storytelling with visuals.


➔ ​ Install Seaborn and compare it with Matplotlib.
➔ ​ Create statistical plots (distribution, box, violin, count,

heatmap).
➔ ​ Use regression and correlation plots for analysis.
➔ ​ Adjust themes and palettes for professional



presentation.
➔ ​ Apply Seaborn to summarize multivariate data

efficiently.


**Plotly Interactive**
**Plots** ➔​ Build interactive charts using Plotly’s core functions.


➔​ Create dynamic line, scatter, and time-series plots.


➔​ Customize interactivity (hover, zoom, filters).


➔​ Export or embed interactive visuals for web use.


**Plotly Advanced** ➔ ​ Design simple interactive dashboards with Plotly

Dash.
➔ ​ Add animations and transitions to enhance

storytelling.
➔ ​ Combine multiple charts into cohesive layouts.
➔ ​ Save and share dashboards or notebooks effectively.



**Plotly**
**Geo-Visualization**


v8.0.0



➔ ​ Understand geospatial data visualization concepts.
➔ ​ Create base maps with Plotly Express.
➔ ​ Add advanced geographic layers (bubbles,

choropleths).
➔ ​ Integrate maps with time or category-based data.



32


​

​ ​



**PygWalker: Tableau in**
**Your Jupyter**
**Notebook**


v8.0.0



➔ ​ Install and run PygWalker inside Jupyter Notebook.
➔ ​ Create quick, drag-and-drop style visualizations.
➔ ​ Customize charts without code for faster exploration.
➔ ​ Export and present visuals like a Tableau dashboard.



33


​

​ ​

## **Program 5: From Data to AI**

### Module 1: Introduction to Data Science

##### **Introduction**

This module provides a comprehensive overview of the data science field—its concepts, processes,
specializations, and career paths. Learners will explore how data science transforms raw information into
insights that drive decisions and innovation across industries. Through real-world examples, they will
understand the data science life cycle, discover diverse specializations like machine learning and NLP, and
evaluate how data-driven decision-making creates measurable impact. The module concludes with guidance
on essential skills, tools, and roles to prepare learners for a successful career in data science.
##### **Learning Objectives**


By the end of this module, the learner will be able to:


➔​ Describe the role and societal impact of data science.


➔​ Explain the stages of the data science process and their importance.


➔​ Identify major specializations within data science and their applications.


➔​ Analyze real-world data-driven case studies to extract insights and lessons.


➔​ Evaluate how organizations use data to make evidence-based decisions.


➔​ Compare required skills and techniques across data science career paths.


➔​ Assess personal strengths and interests to align with a suitable data science specialization.
##### **Content**


**Topic** **Learning Outcomes**


**Data Science Concepts** ➔ ​ Describe the role of data science in modern society.
➔ ​ Explain the key components of the data science

process, including data collection, cleaning, analysis,
and visualization.
➔ ​ Identify the importance of data in various industries.
➔ ​ Demonstrate how data science can provide

actionable insights.
➔ ​ Recognize common tools and technologies used in

data science, such as programming languages (e.g.,
Python, R) and data analysis libraries.


v8.0.0

34


​

​ ​



**Different**
**Specializations in**
**Data Science**


**The Data Science**
**Process**


**Use Cases and**
**Data-Driven**
**Decision-Making**



➔ ​ Describe specializations within data science,

including machine learning, big data analytics,
natural language processing, and computer vision.
➔ ​ Compare and contrast different data science



➔ ​ Describe the stages of the data science life cycle,

including data collection, cleaning, exploration,
modeling, and evaluation.
➔ ​ Explain the importance of each stage and the

techniques used within each phase.


➔​ Describe the concept of data-driven decision-making

and its significance in business and other domains.
➔​ Explain how data can inform and validate decisions,

and optimize processes and strategies.
➔​ Analyze case studies of organizations that have



specializations based on their applications,
techniques, and required skill sets.
➔ ​ Analyze case studies and examples of real-world



projects across various data science specializations.
➔ ​ Evaluate personal interests and career goals to



identify which data science specialization aligns with
individual skills and aspirations.



successfully implemented data-driven
decision-making.
➔​ Apply data analysis techniques to make informed

decisions in various scenarios.


**Careers in Data**
**Science** ➔​ Identify the educational and professional background

typically required for a career in data science.
➔ ​ Explore the demand for data science professionals

across various industries and regions.
➔ ​ Describe the job opportunities and career paths

available in the field of data science.
➔ ​ Identify the core skills and competencies needed to

succeed in a data science career.



v8.0.0



35


​

​ ​

### Module 2: Introduction to Databases Management

##### Introduction ​

In this module, you will be introduced to the fundamentals of database management. You will learn about

the purpose and benefits of using databases, key concepts such as data models, relational databases, and

NoSQL databases. Additionally, you will explore various database management systems (DBMS) and their

role in handling data.
##### **Learning Objectives**


By the end of this module, the learner will be able to:

➔ ​ Describe the purpose and benefits of using databases.
➔ ​ Compare different data models and their applications.
➔ ​ Explain the structure and querying capabilities of relational databases.
➔ ​ Identify the unique characteristics of NoSQL databases.
➔ ​ Differentiate among various DBMS (Database Management System) options available.

##### **Content**


**Topic** **Learning Outcomes**


**Basics of databases** ➔ ​ Describe the purpose and benefits of using databases.
➔ ​ Explain the key components of a database system.



**Relational vs**
**Non-relational**
**Database**



➔ ​ Differentiate between relational and non-relational

databases
➔ ​ Identify common use cases for different types of



databases


**Relational databases** ➔ ​ Define the concept of a relational database and its

components
➔ ​ Describe the principles and importance of data in

database design



**Database**
**management systems**
**(DBMS)**


**Database Models and**
**Database Scheme**


v8.0.0



➔ ​ Describe the role and functions of a DBMS in managing

databases
➔ ​ Identify popular DBMSs and their characteristics
➔ ​ Explain the concept and role of a data model
➔ ​ Describe the structure and elements of a database

schema


➔ ​ Explain the purpose and types of database models and

their role in structuring data.



36


​

​ ​


➔ ​ Interpret and design Entity-Relationship Diagrams (ERDs)

to represent data relationships.
➔ ​ Define and document database schemas, including

tables, keys, and relationships.
➔ ​ Apply best practices in database schema design to

ensure consistency and efficiency.
➔ ​ Evaluate database design decisions based on

performance, scalability, and clarity.


v8.0.0



37


​

​ ​

### Module 3: Introduction to SQL

###### **Introduction**


This mega-module compresses the critical path from relational querying to production-grade data pipelines. You’ll
start by mastering precise multi-table joins, then fortify data quality with systematic cleaning patterns. We extend
aggregation into advanced, multi-stage KPIs; add expressive power with subqueries; and preserve row granularity
using window functions. You’ll factor complex logic with CTEs, read and influence query plans through indexing
and optimization, and finally operationalize insights by building an end-to-end ETL to SQLite with Python, Pandas,
and lightweight visualization. By the end, you will design, implement, validate, optimize, and ship reliable SQL
analytics that stand up to real-world demands.

###### Learning Objectives: ​

​
By the end of this module, the learner will be able to :


➔ ​ Differentiate and apply major join types safely.


➔ ​ Profile, clean, and standardize messy datasets reproducibly.


➔ ​ Design multi-level, conditional, and distinct-aware aggregations.


➔ ​ Construct scalar, table, and correlated subqueries with null-safe logic.


➔ ​ Compute rankings, running totals, and moving windows correctly.


➔ ​ Refactor complex queries with non-recursive and recursive CTEs.


➔ ​ Optimize queries via sargability, indexing, and plan interpretation.


➔ ​ Engineer an idempotent ETL from raw files to analytics tables with validation.


➔ ​ Validate results using reconciliation checks and instrumentation.


➔ ​ Document assumptions, trade-offs, and performance impacts clearly.


**Topic** **Learning Outcomes**



**SQL Data Joins**
➔ ​ Write INNER, LEFT, RIGHT, FULL, and CROSS



joins with clear aliases.
➔ ​ Construct predicates that prevent Cartesian



products and duplication.
➔ ​ Apply self-joins for comparisons and hierarchies.
➔ ​ Implement anti-joins and semi-joins with NOT



v8.0.0



38


​

​ ​



EXISTS / EXISTS safely.
➔ ​ Diagnose row loss or explosion and validate



cardinality.
➔ ​ Assess join order and selectivity; justify chosen



strategies.
➔ ​ Leverage supporting indexes for join keys.



**Data Cleaning**
➔ ​ Profile nulls, outliers, and type inconsistencies.
**Techniques**
➔ ​ CAST/CONVERT deliberately and validate



ranges.
➔ ​ Standardize strings, dates, and categorical



values.
➔ ​ De-duplicate records using window functions



(e.g., ROW_NUMBER).
➔ ​ Enforce integrity with keys and constraints.
➔ ​ Stage fixes in repeatable, auditable steps.
➔ ​ Log exceptions and quantify residual quality risk.



**Advanced**
➔ ​ Decompose complex KPIs into multi-stage
**Aggregations**



aggregates.
➔ ​ Build conditional metrics with SUM(CASE …)



patterns.
➔ ​ Compute distinct-aware measures and explain



trade-offs.
➔ ​ Produce multi-level summaries (rollups/cubes or



emulations).
➔ ​ Reconcile totals across levels and document



invariants.
➔ ​ Blend aggregates with window functions where



appropriate.
➔ ​ Refactor aggregation logic for readability and



reuse.



**Nested Queries &**
➔ ​ Embed scalar and table subqueries effectively.
**Subqueries**
➔ ​ Compose correlated subqueries and predict



performance costs.
➔ ​ Select EXISTS/IN versus joins with null-safe



reasoning.
➔ ​ Refactor dense subqueries into CTEs for clarity.
➔ ​ Verify equivalence between alternative



formulations.
➔ ​ Guard single-row assumptions and test edge



cases.



v8.0.0



39


​

​ ​


➔ ​ Encourage predicate pushdown when feasible.



**Window Functions**
➔ ​ Specify OVER() partitions, ordering, and frames



correctly.
➔ ​ Compute ranks and percent-of-total metrics.
➔ ​ Build running totals and moving averages

without leakage.
➔ ​ Use LAG/LEAD for period deltas and change



detection.
➔ ​ Stabilize sort keys to ensure deterministic



windows.
➔ ​ Validate frame boundaries against business



logic.
➔ ​ Benchmark window costs and optimize when



needed.



**Common Table**
➔ ​ Modularize queries with well-named
**Expressions (CTEs)**



non-recursive CTEs.
➔ ​ Implement recursive traversals with safe



termination.
➔ ​ Compare CTEs with subqueries, views, and temp



tables.
➔ ​ Assess materialization/optimization impacts



and adjust.
➔ ​ Chain CTEs to isolate concerns and reuse



intermediates.
➔ ​ Document data flow and test stepwise.
➔ ​ Avoid over-nesting and related anti-patterns.



**Indexing &**
➔ ​ Explain seeks versus scans and relate selectivity
**Optimization**



to index value.
➔ ​ Design composite and covering indexes aligned



to predicates.
➔ ​ Write sargable predicates (avoid



function-wrapped columns).
➔ ​ Interpret plans to identify join strategies and



hotspots.
➔ ​ Balance read performance with write and



maintenance costs.
➔ ​ Measure improvements with representative



benchmarks.
➔ ​ Document changes and monitor for regressions.



v8.0.0



40


​

​ ​



**ETL to SQLite with**
**Python (Pandas &**
**Matplotlib)**


v8.0.0



➔ ​ Extract CSV/JSON, infer or set data types, and

validate schema.
➔ ​ Transform with Pandas (clean, join, aggregate)



and unit-test helpers.
➔ ​ Load idempotently to SQLite with batched,

parameterized writes.
➔ ​ Upsert safely and reconcile counts against



sources.
➔ ​ Visualize KPIs and anomalies with simple plots.
➔ ​ Automate runs and log quality checks.
➔ ​ Package a reproducible pipeline artifact.



41


​

​ ​

### Module 4: Introduction to API Development

###### **Introduction**


Turning a trained model into business value requires reliable, secure, and observable serving. This module guides
you from first principles—why APIs are the preferred interface for ML inference—through the practical skills to
build, test, secure, and operate a production-grade service. You’ll design clean endpoints for prediction, health,
and feedback, implement them in FastAPI, and validate inputs with Pydantic to protect your model. You’ll add
structured logging and robust error handling, exercise your API with curl and Postman, secure endpoints using API
keys or tokens, and run with Uvicorn or Gunicorn for concurrency and resilience.

###### Learning Objectives: ​

​
By the end of this module, the learner will be able to :


➔ ​ Explain why APIs are the standard interface for deploying ML inference.


➔ ​ Apply REST and JSON conventions to design predictable ML endpoints.


➔ ​ Implement /predict, /health, and /feedback with FastAPI.


➔ ​ Validate requests and responses using Pydantic models.


➔ ​ Handle errors gracefully and emit structured, actionable logs.


➔ ​ Secure endpoints with API keys or tokens and least-privilege practices.


➔ ​ Test endpoints using curl and Postman collections.


➔ ​ Run and tune Uvicorn/Gunicorn workers for concurrent inference.


➔ ​ Document API contracts and non-functional requirements.


➔ ​ Monitor basic SLOs (latency, throughput, error rate) for model serving.


**Topic** **Learning Outcomes**



**Why APIs matter for deploying**

**ML models**


v8.0.0



➔ ​ Articulate the business and engineering benefits



of API-based inference.
➔ ​ Differentiate online, batch, and streaming serving



modes.
➔ ​ Relate latency, throughput, and cost constraints



to API design.
➔ ​ Map model lifecycle stages to serving



42


​

​ ​




































|Col1|requirements.<br>➔​ Identify anti-patterns (e.g., raw notebook servers)<br>and propose fxi es.|
|---|---|
|**REST, JSON, and**<br>**request–response**<br>**basics for ML**<br>**engineers**|➔​ Apply HTTP verbs, status codes, and content<br>types consistently. <br>➔​ Design JSON payloads for inputs, outputs, and<br>metadata. <br>➔​ Use idempotency and correlation IDs for<br>reliability. <br>➔​ Negotiate versioning strategies for evolving<br>schemas. <br>➔​ Document contracts with examples and edge<br>cases.|
|**Designing clean**<br>**endpoints: /predict,**<br>**/health, /feedback**|➔​ Specify request/response schemas for each<br>endpoint. <br>➔​ Separate readiness vs liveness health checks. <br>➔​ Capture user and model feedback safely for<br>retraining. <br>➔​ Defne error models and standardized<br>responses. <br>➔​ Establish performance budgets and timeouts.|
|**Using FastAPI**|➔​ Bootstrap a FastAPI app with routers and<br>dependency injection. <br>➔​ Load and cache models efciently at startup. <br>➔​ Annotate endpoints with type hints for automatic<br>docs. <br>➔​ Return streaming or background tasks when<br>appropriate. <br>➔​ Integrate middleware for CORS and request<br>context.|
|**Test API with curl or**<br>**Postman requests**|➔​ Craft curl commands for happy-path and<br>failure-path tests. <br>➔​ Build a Postman collection with environment<br>variables. <br>➔​ Automate smoke tests in CI with Newman. <br>➔​ Assert on status codes, schema, and latency.|



v8.0.0



43


​

​ ​























|Col1|➔​ Record and share reproducible test cases.|
|---|---|
|**Add request validation**<br>**with Pydantic**|➔​ Defne input/output models with constraints and<br>defaults. <br>➔​ Validate shapes, ranges, and categorical values. <br>➔​ Serialize model predictions with clear typing. <br>➔​ Centralize validation errors into consistent<br>responses. <br>➔​ Version schemas without breaking clients.|
|**Implement error**<br>**handling and**<br>**structured logging**|➔​ Create exception handlers that preserve context. <br>➔​ Emit structured logs (JSON) with correlation IDs. <br>➔​ Classify errors (client, server, dependency) and<br>map to codes. <br>➔​ Redact sensitive inputs from logs. <br>➔​ Expose minimal diagnostics via /health and<br>metrics.|
|**Secure endpoints using**<br>**API keys or tokens**|➔​ Protect endpoints with API keys, bearer tokens,<br>or OAuth2 fows. <br>➔​ Implement dependency-based auth in FastAPI. <br>➔​ Scope permissions to least privilege and rotate<br>secrets. <br>➔​ Enforce HTTPS and CORS policies. <br>➔​ Audit access and rate-limit abusive clients.|
|**Run server with**<br>**Uvicorn/Gunicorn for**<br>**concurrency**|●​ Choose worker types (sync, async, uvicorn<br>workers) for workload. <br>●​ Tune worker count and timeouts for CPU/GPU<br>inference. <br>●​ Enable keep-alive and HTTP/1.1 for throughput. <br>●​ Gracefully handle startup/shutdown events and<br>warm caches. <br>●​ Containerize and confgure health probes for<br>orchestration.|


v8.0.0













44


​

​ ​

## **Program 6: Machine Learning**

### Module 1: Introduction to AI & Machine Learning

###### **Introduction**


This module introduces the core principles, evolution, and applications of Artificial Intelligence (AI) and
Machine Learning (ML). Learners will explore AI’s history, types, and real-world impact across industries,
along with ethical considerations. The module explains how AI systems leverage data and algorithms to
make intelligent decisions, while providing a structured overview of ML paradigms, workflows, and essential
algorithms. By the end, learners will have hands-on understanding of building and evaluating ML models
using **Scikit-learn**, bridging theory with applied practice in data-driven intelligence.

###### Learning Objectives: ​

​
By the end of this module, the learner will be able to :


➔ ​ Define artificial intelligence and describe its evolution and societal importance.


➔ ​ Differentiate between AI, machine learning, and data science.


➔ ​ Classify types of AI (narrow, general, superintelligent) and paradigms (symbolic vs. non-symbolic).


➔ ​ Explain key ML concepts including regression, classification, clustering, and dimensionality reduction.


➔ ​ Outline the ML workflow—data preparation, training, evaluation, and deployment.


➔ ​ Apply foundational ML algorithms using Scikit-learn for supervised and unsupervised learning.


➔ ​ Evaluate model performance and optimize results through cross-validation and hyperparameter

tuning.

|Content|Col2|
|---|---|
|**Topic**|**Learning Outcomes**|
|**Introduction to AI**<br>➔​<br>Defne artifcial intelligence and its primary<br>objectives.<br>➔​<br>Learn the historical context and evolution of<br>AI.<br>➔​<br>Understand why AI is important in modern<br>society.<br>➔​<br>Learn about the impact of AI across various<br>industries, such as healthcare, fnance, and|**Introduction to AI**<br>➔​<br>Defne artifcial intelligence and its primary<br>objectives.<br>➔​<br>Learn the historical context and evolution of<br>AI.<br>➔​<br>Understand why AI is important in modern<br>society.<br>➔​<br>Learn about the impact of AI across various<br>industries, such as healthcare, fnance, and|



v8.0.0

45


​

​ ​



|transportation.<br>➔​ Discuss ethical considerations and<br>challenges in AI.<br>➔​ Explore how AI leverages data science and<br>data analysis to make intelligent decisions.<br>➔​ Learn about the role of data in training AI<br>models.<br>➔​ Understand the similarities and difef rences<br>between AI, machine learning, and data science.|Col2|
|---|---|
|**Types of AI**<br>➔​ Understand the distinctions between narrow AI,<br>general AI, and superintelligent AI.<br>➔​ Learn about diferent AI paradigms, including<br>symbolic AI, rule-based systems, and neural<br>networks.|**Types of AI**<br>➔​ Understand the distinctions between narrow AI,<br>general AI, and superintelligent AI.<br>➔​ Learn about diferent AI paradigms, including<br>symbolic AI, rule-based systems, and neural<br>networks.|
|**Introduction to**<br>**Machine Learning**|➔​ Defne what machine learning is.<br>➔​ Explain the importance of machine<br>learning.<br>➔​ Identify and describe the types of<br>machine learning.<br>➔​ Defne what regression is.<br>➔​ Defne what classifcation is. <br>➔​ Explain what clustering is. <br>➔​ Describe the concept of dimensional reduction. <br>➔​ Identify and explain the association<br>rule.<br>➔​ Defne what anomaly detection is.<br>➔​ Defne what Q-learning is.<br>➔​ Explain the concept of<br>neuro-evolution.|
|**AI Types and Paradigms**|➔​ Explain the concept of symbolic AI.<br>➔​ Provide examples of symbolic AI<br>applications.<br>➔​ Describe expert systems and<br>rule-based systems within the<br>context of symbolic AI.<br>➔​ Explain the concept of non-symbolic<br>AI.<br>➔​ Provide examples of non-symbolic AI|


v8.0.0





46


​

​ ​



|Col1|applications.|
|---|---|
|**Machine Learning Workfow and**<br>**Algorithms**|➔​ Examine key machine learning<br>algorithms, including linear<br>regression, decision trees, k-nearest<br>neighbors, and support vector<br>machines.<br>➔​ Outline the machine learning<br>workfow, including data collection,<br>preprocessing, model training,<br>evaluation, and deployment.<br>➔​ Discuss the importance of feature<br>engineering and model selection in<br>machine learning.<br>➔​ Explain the concepts of overftting<br>and underftting, and describe<br>methods to address them.|
|**Sci-kit Machine**<br>**Learning Framework**<br>➔​ Explain the purpose and key components of the<br>Sci-Kit Learn framework in Python’s ML<br>ecosystem.<br>➔​ Build and train basic supervised and<br>unsupervised models using sklearn’s unifed<br>API.<br>➔​ Apply data preprocessing techniques (scaling,<br>encoding, splitting) using sklearn utilities.<br>➔​ Evaluate model performance using metrics such<br>as accuracy, precision, recall, and confusion<br>matrix.<br>➔​ Implement cross-validation and<br>hyperparameter tuning with GridSearchCV or<br>RandomizedSearchCV to improve results.|**Sci-kit Machine**<br>**Learning Framework**<br>➔​ Explain the purpose and key components of the<br>Sci-Kit Learn framework in Python’s ML<br>ecosystem.<br>➔​ Build and train basic supervised and<br>unsupervised models using sklearn’s unifed<br>API.<br>➔​ Apply data preprocessing techniques (scaling,<br>encoding, splitting) using sklearn utilities.<br>➔​ Evaluate model performance using metrics such<br>as accuracy, precision, recall, and confusion<br>matrix.<br>➔​ Implement cross-validation and<br>hyperparameter tuning with GridSearchCV or<br>RandomizedSearchCV to improve results.|


v8.0.0





47


​

​ ​

### Module 2: Supervised Learning

###### **Introduction**


In this module, you will focus on one of the key branches of machine learning, where models are trained
using labeled datasets to make predictions or classifications. This module delves into the various algorithms
and techniques employed in supervised learning and provides learners with a comprehensive
understanding of its applications and methodologies.
###### **Learning Objectives:**


By the end of this module, the learner will be able to


➔ ​ Explain the principles and applications of supervised learning.


➔ ​ Describe various regression algorithms and their suitability for different problem domains.


➔ ​ Identify and apply classification algorithms for predicting discrete outcomes.


➔ ​ Explain ensemble methods and their role in improving model performance.


➔ ​ Use evaluation metrics for regression and classification tasks, and interpret the results.


➔ ​ Develop skills in model selection and hyperparameter tuning for optimal performance.


➔ ​ Analyze real-world applications of supervised learning across different industries.

|Content|Col2|
|---|---|
|**Topic**|**Learning Outcomes**|
|**Regression**|➔​ Explain the concept and applications<br>of regression from mathematical<br>perspective such as predicted and<br>actual values representation.<br>➔​ Diferentiate between regression and<br>classifcation tasks.<br>➔​ Identify common evaluation metrics<br>for regression tasks, such as Mean<br>Squared Error (MSE), Root Mean<br>Squared Error (RMSE), and Mean<br>Absolute Error (MAE).<br>➔​ Interpret evaluation metrics to assess<br>model performance and accuracy.<br>➔​ Compare the diferences between<br>linear and polynomial regression.<br>➔​ Discuss the suitability of each|



v8.0.0

48


​

​ ​
















|Col1|regression type for difef rent problem<br>domains.|
|---|---|
|**Regression Models**|➔​ Explain the mathematical principles behind linear<br>regression. <br>➔​ Describe multi-linear regression and polynomial<br>regression. <br>➔​ Explore regularization techniques such as Lasso<br>and Ridge regression. <br>➔​ Derive the ordinary least squares (OLS) method<br>for ftting a linear regression model. <br>➔​ Interpret regression coefcients and conduct<br>signifcance testing. <br>➔​ Extend linear regression to model relationships<br>with multiple predictors. <br>➔​ Interpret coefcients in the context of multiple<br>predictors. <br>➔​ Introduce polynomial regression and explain its<br>ability to capture nonlinear relationships. <br>➔​ Analyze the impact of diferent polynomial<br>degrees on model fexibility. <br>➔​ Explain Lasso and Ridge regression as<br>regularization techniques to prevent overftting. <br>➔​ Implement regularization techniques in<br>regression models. <br>➔​ Describe logistic regression and its application in<br>binary classifcation tasks.|
|**Classifcation Models**|➔​ Explain the concept of conditional<br>probability and its role in classifcation.<br>➔​ Apply classifcation evaluation metrics<br>and interpret their results.<br>➔​ Review conditional probability and<br>discuss its importance in classifcation<br>tasks.<br>➔​ Explain Bayes' theorem and its<br>application in probabilistic<br>classifcation.<br>➔​ Identify common evaluation metrics<br>for classifcation tasks, such as<br>accuracy, precision, recall, and<br>F1-score.|



v8.0.0



49


​

​ ​


➔ ​ Evaluate model performance and

accuracy using these classification
metrics.
➔ ​ Describe various classification

algorithms, including Naive Bayes,
Decision Trees, and Support Vector
Machines (SVM).
➔ ​ Examine ensemble methods such as

Random Forest and Gradient Boosting.
➔ ​ Explain Bayes' rule and its application

in Naive Bayes classification.
➔ ​ Implement the Naive Bayes algorithm

for probabilistic classification.
➔ ​ Explain the concept of decision trees

and their use in classification tasks.
➔ ​ Analyze the mathematical principles

behind decision tree construction and
splitting criteria.
➔ ​ Describe the concept of support

vectors and the maximum margin
hyperplane.
➔ ​ Explain SVM parameters and kernel

functions for nonlinear classification.
➔ ​ Introduce ensemble methods such as

Random Forest and Gradient Boosting.
➔ ​ Describe the principles of bagging and

boosting for improving model
performance.


v8.0.0



50


​

​ ​

### Module 3: Unsupervised Learning

###### **Introduction**


In this module, you will focus on the branch of machine learning where models are trained on unlabeled
data to discover patterns, relationships, and structures within the dataset. This module introduces learners
to various algorithms and techniques used in unsupervised learning and explores their applications in data
exploration, clustering, and dimensionality reduction.
###### **Learning Objectives:**


By the end of this module,the learner will be able to :


➔​ Explain the principles and applications of unsupervised learning.
➔​ Describe different clustering algorithms and determine their suitability for various types of data.
➔​ Apply dimensionality reduction techniques to extract meaningful information from high-dimensional

data.
➔​ Explore association rule learning and its applications in market basket analysis and recommendation

systems.
➔​ Implement anomaly detection techniques to identify outliers and unusual patterns in data.
➔​ Evaluate unsupervised learning models using appropriate metrics.
➔​ Analyze real-world applications of unsupervised learning across different industries.



|Content|Col2|
|---|---|
|**Topic**|**Learning Outcomes**|
|**Clustering**|➔​ Defne unsupervised learning and explain its<br>importance. <br>➔​ Identify the types of unsupervised learning. <br>➔​ Explain the concept of clustering. <br>➔​ Compare diferent clustering algorithms. <br>➔​ Apply the K-means clustering algorithm to<br>datasets. <br>➔​ Explain the principles behind various distance<br>calculations used in clustering. <br>➔​ Implement hierarchical clustering and interpret<br>dendrograms. <br>➔​ Master the implementation of the DBSCAN<br>algorithm for density-based clustering. <br>➔​ Use evaluation metrics to assess the|


v8.0.0





51


​

​ ​



|Col1|performance of clustering algorithms.|
|---|---|
|**Principal component**<br>**analysis**|➔​ Explain the concept of dimensionality<br>reduction.<br>➔​ Compare diferent dimensionality<br>reduction methods, including Principal<br>Component Analysis (PCA).<br>➔​ Describe the mathematical concepts of<br>eigenvectors and eigenvalues.<br>➔​ Implement PCA for dimensionality<br>reduction.<br>➔​ Analyze the signifcance of<br>eigenvectors and eigenvalues in PCA.<br>➔​ Practice the PCA algorithm to reduce<br>the dimensionality of data.<br>➔​ Execute PCA steps, including mean<br>centering, covariance matrix<br>computation, and<br>eigendecomposition.<br>➔​ Identify applications of dimensionality<br>reduction in various felds.|
|**Association Rule**<br>**Learning and Anomaly**<br>**Detection**|➔​ Familiarize with association rule<br>learning concepts.<br>➔​ Examine key algorithms for association<br>rule learning.<br>➔​ Describe the evaluation metrics used<br>for association rules.<br>➔​ Defne anomaly detection and its<br>importance.<br>➔​ Compare diferent anomaly detection<br>methods.<br>➔​ Identify the applications of anomaly<br>detection in various felds.|


v8.0.0













52


​

​ ​

### Module 4: Time Series Analysis


**Introduction**


In this module, we will explore the fundamentals of time series data, understanding what sets it apart from

other types of data. We will delve into the unique properties of time series data and the various tasks

commonly associated with it, such as trend analysis, seasonal decomposition, and forecasting. Additionally,

we will provide a comprehensive overview of the basic models and techniques used for time series analysis,

including statistical methods and machine learning approaches. By the end of this module, you will have a

solid foundation in time series analysis and be equipped with the skills to apply these techniques effectively.


**Learning Objectives**


By the end of this module, learners will be able to:


➔ ​ Explain the fundamentals of time series analysis.

➔ ​ Explore and visualize time series data using appropriate tools and techniques.

➔ ​ Differentiate between stationary and non-stationary time series.

➔ ​ Apply trend and statistical analysis techniques to time series data.

➔ ​ Forecast future values and detect anomalies in time series data.


**Content**


**Topic** **Learning Outcomes**



**Time Series**


**Time Series Data**

**Exploration and**

**Visualization**


v8.0.0



➔​ Define time series data and explain its importance.

➔​ Identify examples of time series data across various

domains, such as finance, healthcare, and weather

forecasting.

➔​ Describe the components of time series: Trend,

Seasonal, Cyclical, and Irregular.

➔​ Differentiate between stationary and non-stationary

time series.


➔ ​ Plot time series data using appropriate visualization

techniques.

➔ ​ Identify trends, seasonality, and noise in time series

data.



53


​

​ ​


➔ ​ Explain the decomposition of time series data into its

components: trend, seasonal, and residual.



**Time Series Statistical**

**Analysis**


**Time Series**

**Forecasting and**

**Machine Learning**

**Approaches**


**Anomaly Detection in**

**Time Series**


v8.0.0



➔​ Identify and analyze trend components in time series

data.

➔​ Apply moving averages and exponential smoothing

techniques for trend analysis.

➔​ Implement Autoregressive (AR) models, Moving

Average (MA) models, and ARIMA (Autoregressive

Integrated Moving Average) models, including

Seasonal ARIMA (SARIMA) models.

➔​ Explore advanced variants such as SARIMA (Seasonal

ARIMA) and ARIMAX (ARIMA with exogenous

variables).


➔ ​ Distinguish between one-step ahead forecasting and

multi-step forecasting.

➔ ​ Evaluate forecasting models using metrics such as

Mean Absolute Error (MAE) and Mean Squared Error

(MSE).

➔ ​ Apply time series-specific cross-validation techniques.

➔ ​ Perform feature engineering for time series data,

including the creation of lag features and rolling

statistics.

➔ ​ Utilize modern regression-based models and

decision tree-based models (Random Forest,

Gradient Boosting, XGBoost, LightGBM, CatBoost) for

prediction.

➔ ​ Implement Support Vector Machines (SVM) for time

series analysis where applicable.


➔ ​ Identify types of anomalies in time series data.

➔ ​ Apply techniques for anomaly detection, such as

Z-score and Isolation Forest.

➔ ​ Analyze real-world applications of anomaly detection

in various domains.



54


​

​ ​

### Module 5: Recommendation Systems


**Introduction**


In this module, you will be provided with an overview of the fundamental concepts of recommendation

systems. The aim is to understand the principles, importance, and various applications of recommendation

systems. You will gain insights into the types of data used, the preprocessing techniques required, and the

evaluation metrics needed to assess the performance of these systems. This foundational knowledge will

help you determine the appropriate recommendation techniques to apply and understand the challenges

and solutions associated with them.


**Learning Objectives**


By the end of this module, learners will be able to:


➔ ​ Understand the principles, importance, and various applications of recommendation systems.

➔ ​ Gain knowledge of data preprocessing, feature engineering, and evaluation metrics to assess

recommendation system performance.

➔ ​ Understand and implement user-based and item-based collaborative filtering, addressing challenges

like cold start, scalability, and sparsity.

➔ ​ Learn and apply content-based filtering methods, including feature extraction techniques and hybrid

systems, with model evaluation and tuning.

➔ ​ Comprehend and implement matrix factorization techniques such as SVD and ALS, and evaluate and

optimize these models using practical applications and case studies.


**Content**


**Topic** **Learning Outcomes**



**Introduction to**

**Recommendation**

**Systems**


v8.0.0



➔ ​ Define and explain the importance of

recommendation systems.

➔ ​ Identify the different types of recommendation

systems.

➔ ​ Recognize various use cases and applications of

recommendation systems.

➔ ​ Describe the types of data used in recommendation

systems.

➔ ​ Apply data preprocessing techniques for

recommendation systems.



55


​

​ ​


➔ ​ Implement feature engineering techniques for

enhancing recommendation system performance.



**Collaborative Filtering**

**Techniques**


**Content-Based**

**Filtering Techniques**


**Matrix Factorization**

**Techniques**


v8.0.0



➔​ Explain the concept and methodology of user-based

collaborative filtering.

➔​ Analyze similarity measures such as Cosine and

Pearson correlations.

➔​ Implement user-based collaborative filtering using

Python.

➔​ Describe the concept and methodology of

item-based collaborative filtering.

➔​ Implement item-based collaborative filtering using

Python.

➔​ Identify the cold start problem and evaluate its

solutions.

➔​ Discuss scalability issues in collaborative filtering.

➔​ Investigate solutions to the sparsity problem in

collaborative filtering.


➔ ​ Explain the concept and methodology of

content-based filtering.

➔ ​ Apply feature extraction techniques from content.

➔ ​ Implement content-based filtering using Python.

➔ ​ Describe TF-IDF and Word2Vec techniques for

handling text data.

➔ ​ Explore hybrid systems that combine collaborative

and content-based filtering.

➔ ​ Apply cross-validation techniques for model

evaluation.

➔ ​ Perform hyperparameter tuning to optimize models.

➔ ​ Analyze practical examples and case studies to

understand real-world applications.


➔ ​ Explain Singular Value Decomposition (SVD) and

Alternating Least Squares (ALS).

➔ ​ Implement matrix factorization techniques using

Python, specifically with the Surprise library.



56


​

​ ​


➔ ​ Analyze practical applications and case studies of

matrix factorization.

➔ ​ Apply model evaluation techniques to assess matrix

factorization models.

➔ ​ Perform hyperparameter tuning to optimize matrix

factorization models.

➔ ​ Implement optimization techniques using Python.


v8.0.0



57


​

​ ​

## **Program 7: Deep Learning**

### Module 1: Neural Networks

###### **Introduction**


Build a clear, practical foundation in neural networks. You’ll learn core building blocks—neurons, layers, and
activation functions—and how training works via forward pass, loss computation, gradient descent, and
backpropagation. We’ll compare common network families (feedforward, CNNs, RNNs) and map each to real
applications across vision, language, and speech. By the end, you’ll understand how design choices
(architecture, activations, loss) affect performance and how to reason about model behavior on real-world
tasks.
###### **Learning Objectives:**


By the end of this module, the learner will be able to :


➔ ​ Define neurons, layers, and activation functions in neural networks.


➔ ​ Explain forward propagation, loss computation, gradient descent, and backpropagation.


➔ ​ Differentiate activation functions and analyze their impact on learning.


➔ ​ Distinguish FFNs, CNNs, and RNNs by architecture and use cases.


➔ ​ Select appropriate loss functions for supervised tasks.


➔ ​ Apply training steps to a simple model and summarize backprop stages.


➔ ​ Evaluate neural network applications in vision, NLP, and speech, linking task to model type.
##### **Content**


**Topic** **Learning Outcomes**



**Neural Networks**


v8.0.0



➔ ​ Describe the basics of neural networks

and their components, including neurons,
layers, and activation functions.
➔ ​ Examine the process of training neural

networks, including forward propagation,
backpropagation, and gradient descent.
➔ ​ Discuss the applications of neural

networks in areas like image recognition,
natural language processing, and speech
recognition.



58


​

​ ​



**Activation Functions**


**Training Neural**
**Networks**


**Deep machine**
**learning applications**


**Types of Neural**
**Networks**


v8.0.0



➔ ​ Describe different activation functions used in neural

networks.
➔ ​ Analyze the impact of activation functions on neural

network performance.


➔ ​ Examine the process of training neural networks,

including forward propagation, backpropagation, and
gradient descent.
➔ ​ Explain the role of loss functions in training neural

networks.
➔ ​ Introduce and derive the concept of gradient

descent.
➔ ​ Describe the back-propagation algorithm and its

importance in training neural networks.
➔ ​ Summarize the steps involved in the

back-propagation process.


➔ ​ Explain how deep learning models can be used for

image segmentation, machine translation, and
language localization in applications like Google
Translate.
➔ ​ Identify deep learning applications in text analysis,

including sentiment analysis for social media
monitoring, customer feedback analysis, and brand
reputation management.


➔ ​ Identify different types of neural networks, including

feedforward neural networks, convolutional neural
networks (CNNs), and recurrent neural networks
(RNNs).
➔ ​ Describe the architecture and applications of various

types of neural networks.



59


​

​ ​

### Module 2: Machine Learning Frameworks

###### **Introduction**


In this module, you will explore two of the most popular machine learning frameworks: Keras and PyTorch.
These frameworks are widely used for building and deploying machine learning models, particularly in deep
learning. Keras is known for its simplicity and ease of use, making it ideal for rapid prototyping, while
PyTorch offers flexibility and control, making it a favorite among researchers and developers. This module
aims to provide a comprehensive understanding of both frameworks, enabling learners to choose the right
tool for their specific needs and efficiently implement machine learning models.
###### **Learning Objectives:**


By the end of this module, the learner will be able to:


➔ ​ Compare the key features and differences between Keras and PyTorch as machine learning

frameworks.


➔ ​ Build, train, and evaluate machine learning models using both Keras and PyTorch.


➔ ​ Analyze the advantages and trade-offs of using Keras for rapid prototyping and PyTorch for research

and custom model development.


➔ ​ Integrate Keras and PyTorch with other machine learning libraries and tools to enhance model

functionality.


➔ ​ Apply best practices for model deployment, optimization, and troubleshooting in both Keras and

PyTorch.


➔ ​ Evaluate model performance using appropriate metrics and make informed decisions during model

selection.


➔ ​ Examine real-world applications of Keras and PyTorch in various machine learning tasks.



|Content|Col2|
|---|---|
|**Topic**|**Learning Outcomes**|
|**Introduction to Keras**<br>**and PyTorch**<br> <br> <br>|➔​ Explain the background and evolution<br>of Keras and PyTorch as machine<br>learning frameworks.<br>➔​ Describe the fundamental architecture<br>and design philosophy of both Keras<br>and PyTorch.<br>➔​ Compare the key features, strengths,<br>and limitations of Keras and PyTorch.|


v8.0.0





60


​

​ ​



|Col1|➔​ Examine the types of machine learning<br>tasks for which each framework is best<br>suited.<br>➔​ Explain the importance of choosing the<br>right framework based on project<br>requirements.|
|---|---|
|**Building and Training**<br>**Models with Keras**<br> <br> <br>|➔​ Explain how to set up a development<br>environment for PyTorch.<br>➔​ Explain the process of building neural<br>networks using PyTorch’s dynamic<br>computation graph and custom layers.<br>➔​ Examine how to implement training<br>loops, loss functions, and optimizers in<br>PyTorch.<br>➔​ Apply various optimization techniques,<br>such as gradient clipping and weight<br>decay, in PyTorch.<br>➔​ Identify how to use pre-trained models<br>and transfer learning in PyTorch to<br>improve model performance.|
|**Building and Training**<br>**Models with PyTorch**<br>|➔​ Explain how to set up and confgure a<br>development environment for<br>PyTorch.<br>➔​ Describe the process of constructing<br>neural networks using PyTorch’s<br>dynamic computation graph and<br>modular layers.<br>➔​ Implement custom training loops,<br>defne loss functions, and apply<br>optimizers to train deep learning<br>models.<br>➔​ Apply optimization strategies such as<br>gradient clipping, learning rate<br>scheduling, and weight decay to<br>improve convergence.<br>➔​ Utilize pre-trained models and<br>perform transfer learning in PyTorch<br>to enhance model accuracy and<br>efciency.<br>|


v8.0.0





61


​

​ ​



|Model Deployment and<br>Optimization|➔​ Describe the deployment options<br>available for models built in Keras and<br>PyTorch.<br>➔​ Explain how to export and deploy<br>models to production environments<br>using both frameworks.<br>➔​ Describe optimization techniques for<br>improving model efcfi iency and<br>reducing inference time.<br>➔​ Describe how to optimize models for<br>specifci hardware, such as GPUs and<br>TPUs, in Keras and PyTorch.<br>➔​ Apply techniques for model<br>compression, quantization, and<br>pruning to optimize model size and<br>speed.|
|---|---|
|**Integration with**<br>**Other Tools and**<br>**Libraries**<br> <br> <br>|➔​ Integrate Keras and PyTorch with<br>other machine learning tools, such as<br>TensorFlow, Scikit-learn, and OpenCV.<br>➔​ Utilize Keras and PyTorch in<br>combination with data processing<br>libraries like Pandas and NumPy.<br>➔​ Leverage Keras and PyTorch for<br>advanced tasks, such as reinforcement<br>learning and generative models.<br>➔​ Apply Keras and PyTorch in distributed<br>training scenarios using tools like<br>Horovod and PyTorch Distributed.<br>➔​ Analyze real-world examples of<br>integrating Keras and PyTorch in<br>complex machine learning pipelines.|


v8.0.0







62


​

​ ​

### Module 3: Machine Learning Tradeoffs

###### **Introduction**


In this module, you will explore the tradeoffs and considerations involved in the design and implementation
of machine learning models. It covers various aspects such as model complexity, training time,
interpretability, generalization, and computational resources. This module aims to give learners a deeper
understanding of the tradeoffs they may encounter and strategies to make informed decisions in different
scenarios.
###### **Learning Objectives:**


By the end of this module, the learner will be able to:


➔ ​ Understand the tradeoffs and considerations involved in machine learning model design
➔ ​ Recognize the bias-variance tradeoff and strategies for achieving optimal model performance
➔ ​ Address overfitting and underfitting issues through appropriate techniques
➔ ​ Evaluate the balance between model complexity and generalization abilities
➔ ​ Comprehend the tradeoff between model interpretability and performance
➔ ​ Consider computational resources and scalability when making model design decisions
➔ ​ Select appropriate evaluation metrics and make informed choices during model selection
➔ ​ Recognize real-world constraints and ethical considerations in machine learning applications



|Content|Col2|
|---|---|
|**Topic**|**Learning Outcomes**|
|**Introduction to**<br>**Machine Learning**<br>**Model Design**<br>|➔​ Explain the tradeofs and<br>considerations involved in machine<br>learning model design.<br>➔​ Recognize real-world constraints and<br>ethical considerations in machine<br>learning applications.<br>➔​ Consider computational resources and<br>scalability when making model design<br>decisions.<br>➔​ Select appropriate evaluation metrics<br>and make informed choices during<br>model selection.|
|**Bias-Variance**<br>**Tradeof and Model**<br>**Complexity**<br>|➔​ Explain the concept of bias and<br>variance in machine learning models.<br>➔​ Compare between bias and variance in<br>model performance.|


v8.0.0











63


​

​ ​



|Col1|➔​ Recognize the tradeof fbetween bias<br>and variance and its impact on model<br>generalization.<br>➔​ Understand the inful ence of model<br>complexity on generalization.<br>➔​ Describe the efef ct of increasing or<br>decreasing model complexity on bias<br>and variance.<br>➔​ Find the optimal level of model<br>complexity for a given problem.|
|---|---|
|**Techniques to Address**<br>**Overftting and Underftting**<br>|➔​ Address overftting and underftting<br>issues through appropriate<br>techniques.<br>➔​ Examine regularization techniques<br>such as L1 and L2 regularization.<br>➔​ Explain how regularization helps in<br>balancing bias and variance.<br>➔​ Apply regularization techniques to<br>improve model performance.<br>➔​ Explain the concept of early stopping<br>in model training.<br>➔​ Explore techniques to monitor model<br>performance during training.<br>➔​ Apply early stopping to prevent<br>overftting and fnd the optimal<br>training iteration.<br>➔​ Understand the concept of data<br>augmentation in machine learning.<br>➔​ Explore various data augmentation<br>techniques, such as fipping, rotation,<br>and noise addition.<br>➔​ Apply data augmentation to increase<br>the size and diversity of the training<br>dataset.<br>➔​ Explain the concept of ensemble<br>methods and their role in reducing<br>bias and variance.<br>➔​ Explore ensemble techniques such as<br>bagging, boosting, and stacking.<br>➔​ Apply ensemble methods to improve<br>model accuracy and robustness.<br>➔​ Comprehend the tradeof between|


v8.0.0















64


​

​ ​



|Col1|model interpretability and<br>performance.<br>➔​ Evaluate the balance between model<br>complexity and generalization abilities.|
|---|---|
|**Hyperparameter Tuning**|➔​ Determine the optimal number of<br>epochs for training models.<br>➔​ Analyze the impact of diferent batch<br>sizes on model training.<br>➔​ Evaluate the efects of epochs and<br>batch size on the training process.<br>➔​ Apply best practices for managing<br>these hyperparameters during model<br>training.<br>➔​ Defne the function and necessity of a<br>learning rate scheduler in model<br>training.<br>➔​ Compare various learning rate decay<br>techniques and assess their<br>efectiveness.<br>➔​ Implement cosine annealing for<br>adaptive learning rate adjustment.<br>➔​ Select appropriate schedulers and<br>optimizers tailored to specifc training<br>requirements.<br>➔​ Explore advanced techniques beyond<br>grid search such as Bayesian<br>optimization, genetic algorithms, and<br>Hyperband.<br>➔​ Justify the use of Bayesian<br>optimization for efcient<br>hyperparameter tuning.<br>➔​ Employ genetic algorithms for robust<br>hyperparameter optimization<br>strategies.<br>➔​ Analyze the efciency of Hyperband as<br>a rapid hyperparameter tuning<br>approach.<br>➔​ Describe the core concepts of<br>hyperparameter tuning.<br>➔​ Summarize traditional tuning<br>techniques and their applications.<br>➔​ Identify tools available for|


v8.0.0















65


​

​ ​



|Col1|hyperparameter tuning and<br>demonstrate their usage.|
|---|---|
|**Accelerating Machine**<br>**Learning with GPU**<br>**Programming**|➔​ Identify the architecture of GPUs and<br>their role in parallel processing.<br>➔​ Compare the performance of GPUs<br>versus CPUs in machine learning tasks.<br>➔​ Describe the basics of CUDA<br>programming for general-purpose<br>computing on GPUs.<br>➔​ Integrate GPU acceleration into<br>popular machine learning frameworks<br>like TensorFlow and PyTorch.<br>➔​ Apply optimization techniques to<br>maximize GPU efciency in machine<br>learning workfows.<br>➔​ Explore real-world applications of GPU<br>programming in deep learning.<br>➔​ Identify common challenges in GPU<br>programming and implement best<br>practices to address them.|
|**Transfer Learning**|➔​ Defne what transfer learning is and<br>explain its signifcance in the feld of<br>artifcial intelligence.<br>➔​ Describe the step-by-step process<br>involved in implementing transfer<br>learning techniques.<br>➔​ Identify key models that are efectively<br>utilized in transfer learning scenarios.<br>➔​ Analyze practical examples that<br>demonstrate the application of<br>transfer learning in real-world<br>situations.<br>➔​ Evaluate the challenges and limitations<br>that are typically encountered with<br>transfer learning projects.<br>➔​ Explain why transfer learning is<br>benefcial and how it contributes to<br>technological advancements.<br>➔​ Illustrate the transformative impact of<br>transfer learning across various<br>industries.|


v8.0.0









66


​

​ ​


➔ ​ Assess specific industrial applications

where transfer learning has
significantly improved outcomes.

### Module 4: Convolutional Neural Networks & Modern Vision (CNNs)

###### **Introduction**


This module builds from image fundamentals to production-grade computer vision. You’ll ground your
intuition in grayscale and RGB pixel representations, then learn how convolutional neural networks extract
features through filters, non-linearities, and pooling. We break down components such as padding, stride,
normalization, and modern architectural patterns. You’ll situate CNNs within today’s landscape—contrasting
them with Vision Transformers and diffusion models—while practicing transfer learning to reach strong
baselines quickly. We close with responsible AI considerations, real-world constraints, and how
infrastructure choices impact training and iteration speed. Labs give you hands-on practice; the sprint retro
turns experience into improvement actions.
###### **Learning Objectives:**


By the end of this module, the learner will be able to:


➔ ​ Explain grayscale vs RGB encodings and their effect on models.


➔ ​ Describe how convolutions, padding, stride, and pooling shape features.


➔ ​ Assemble CNN architectures using common layers and normalization.


➔ ​ Compare CNNs with Vision Transformers and diffusion models conceptually.


➔ ​ Apply transfer learning and fine-tuning for rapid baselines.


➔ ​ Assess ethical risks, data bias, and mitigation strategies.


➔ ​ Evaluate constraints (data, compute, latency) influencing design choices.


➔ ​ Relate infrastructure components to throughput, cost, and velocity.


➔ ​ Execute labs and reflect on results to plan improvements.

|Content|Col2|
|---|---|
|**Topic**|**Learning Outcomes**|
|**Understanding Images &**|➔​ Interpret intensity histograms and normalization|



v8.0.0

67


​

​ ​



|Pixels (Grayscale)|effects.<br>➔​ Prepare grayscale tensors with consistent shapes.<br>➔​ Apply basic augmentations and evaluate impact.<br>➔​ Diagnose label/data leakage in preprocessing.<br>➔​ Document reproducible preprocessing pipelines.|
|---|---|
|**Understanding Images**<br>**& Pixels (RGB)**|➔​ Explain channels, color spaces, and per-channel<br>normalization.<br>➔​ Implement standard transforms and<br>augmentations.<br>➔​ Handle varying resolutions and aspect ratios<br>safely.<br>➔​ Batch and prefetch efciently for GPUs.<br>➔​ Validate input statistics against pretrained model<br>expectations.|
|**Convolutional Neural**<br>**Networks Overview**|➔​ Describe receptive felds and translation<br>equivariance.<br>➔​ Relate flter size, stride, and padding to output<br>shapes.<br>➔​ Compare classic vs modern CNN families at a<br>high level.<br>➔​ Outline training loops, loss functions, and metrics.<br>➔​ Set baselines and guardrails for experiments.|
|**Introduction to Convolutional**<br>**Neural Networks**|➔​ Build a minimal CNN for classifcation.<br>➔​ Use initialization and learning-rate schedules<br>appropriately.<br>➔​ Prevent overftting with regularization and<br>augmentation.<br>➔​ Track experiments and compare runs.<br>➔​ Interpret failure cases to refne data or model.|
|**Components of**<br>**Convolutional Neural**<br>**Networks**|➔​ Use conv/pool/activation/BN/dropout effectively.<br>➔​ Balance depth, width, and compute budgets.<br>➔​ Apply residual/skip connections to stabilize<br>training.<br>➔​ Choose global pooling and heads for tasks.<br>➔​ Profle memory/throughput and optimize input<br>pipelines.|


v8.0.0





68


​

​ ​














|State of the Art in Computer<br>Vision & Vision Transformers|➔​ Contrast inductive biases of CNNs vs ViTs.<br>➔​ Explain patch embeddings and attention at a high<br>level.<br>➔​ Select between CNN/ViT given data size and<br>compute.<br>➔​ Leverage pretrained backbones and adapters.<br>➔​ Design hybrid or staged approaches pragmatically.|
|---|---|
|**Ethics & Responsible AI (RAI)**|➔​ Identify bias sources across data and labels. <br>➔​ Select metrics and audits for fairness. <br>➔​ Propose mitigations (reweighting, augmentation,<br>review). <br>➔​ Plan governance and documentation artifacts. <br>➔​ Communicate limitations to stakeholders.|
|**Constraints & Considerations in**<br>**Model Development**|➔​ Balance accuracy, latency, memory, and cost. <br>➔​ Choose batch sizes and mixed precision<br>appropriately. <br>➔​ Design ablations to isolate effects. <br>➔​ Defne exit criteria and rollback plans. <br>➔​ Track risks and dependencies explicitly.|
|**Infrastructure Components &**<br>**Their Impact on Model Training**|➔​ Relate GPUs/CPUs/storage/network to<br>throughput. <br>➔​ Optimize data loaders and caching. <br>➔​ Schedule experiments for utilization. <br>➔​ Use profling tools to remove bottlenecks. <br>➔​ Estimate cost and time-to-result.|


### Module 5: Model Deployment & Optimization

###### **Introduction**

Deployment turns models into value. This module teaches the end-to-end path from export formats to
high-throughput inference, with a focus on predictable latency, reliability, and cost efficiency. You’ll export
models to SavedModel, ONNX, TF Lite, or TorchScript; evaluate serving stacks; and apply core
optimizations—quantization, pruning, distillation, and compression—while measuring accuracy trade-offs.
You’ll stand up a minimal FastAPI or Streamlit endpoint, add observability and safeguards, and track bias


v8.0.0

69


​

​ ​


and drift in production. The sprint retro converts findings into a concrete action plan and playbooks you can
reuse.
###### **Learning Objectives:**


By the end of this module, the learner will be able to:


➔ ​ Explain why deployment design drives scalability, latency, and reliability.


➔ ​ Export models across common formats and validate parity.


➔ ​ Choose serving tools that match workload and constraints.


➔ ​ Apply quantization, pruning, and distillation with measured trade-offs.


➔ ​ Compress artifacts to reduce footprint and startup time.


➔ ​ Deploy a microservice endpoint for inference.


➔ ​ Monitor accuracy, latency, throughput, and drift ethically.


➔ ​ Run a data-informed retro and capture playbooks.







|Content|Col2|
|---|---|
|**Topic**|**Learning Outcomes**|
|**Why deployment matters:**<br>**scaling, latency, reliability**|➔​ Relate SLOs to architecture and capacity plans.<br>➔​ Design for elasticity, retries, and backpressure.<br>➔​ Defne error budgets and rollback strategies.<br>➔​ Choose batch, online, or streaming inference<br>appropriately.<br>➔​ Quantify cost vs performance trade-offs.|
|**Model export:**<br>**SavedModel, ONNX, TF**<br>**Lite, TorchScript**|➔​ Convert models to target runtimes with tooling.<br>➔​ Validate numeric parity and acceptable drift.<br>➔​ Bundle metadata (pre/post-processing) with<br>artifacts.<br>➔​ Automate export in CI with reproducible confgs.<br>➔​ Document compatibility and fallbacks.|
|**Inference optimization:**<br>**serving tools overview**|➔​ Compare server options for CPU/GPU/edge.<br>➔​ Enable batching, dynamic shapes, and caching.<br>➔​ Confgure parallelism and concurrency safely.<br>➔​ Instrument latency percentiles and throughput.|


v8.0.0



70


​

​ ​









|Col1|➔​ Plan A/B and canary rollouts.|
|---|---|
|**Quantization: FP32→ INT8,**<br>**accuracy vs latency**|➔​ Choose PTQ vs QAT paths.<br>➔​ Select per-tensor vs per-channel schemes.<br>➔​ Create a calibration set and measure deltas.<br>➔​ Mitigate accuracy loss with selective quantization.<br>➔​ Document hardware/runtime constraints.|
|**Pruning: remove low**<br>**weights, visualize**<br>**sparsity**|➔​ Apply magnitude or structured pruning.<br>➔​ Retrain to recover accuracy.<br>➔​ Measure sparse speedups by backend.<br>➔​ Visualize sparsity patterns for analysis.<br>➔​ Archive checkpoints for reversibility.|
|**Model Distillation**|➔​ Defne teacher–student objectives.<br>➔​ Tune temperature and loss weighting.<br>➔​ Pick student capacity for targets.<br>➔​ Evaluate latency/accuracy trade-offs.<br>➔​ Package distilled models for serving.|
|**Compression: smaller, faster**<br>**models**|➔​ Apply weight sharing and low-rank methods<br>conceptually. <br>➔​ Use mixed precision and operator fusion. <br>➔​ Minimize artifacts with zip/pack and lazy load. <br>➔​ Track cold-start and warm-start times. <br>➔​ Set size and latency budgets per release.|
|**Micro deployment:**<br>**FastAPI/Streamlit REST endpoint**|➔​ Expose /predict and /health endpoints. <br>➔​ Validate inputs and handle errors consistently. <br>➔​ Batch requests and cache results when feasible. <br>➔​ Containerize with health probes and resource<br>limits. <br>➔​ Automate smoke tests and basic load tests.|
|**Ethical deployment: bias, drift,**<br>**monitoring**|➔​ Defne monitoring for fairness and drift. <br>➔​ Log privacy-safe features and decisions. <br>➔​ Set thresholds and escalation workfows. <br>➔​ Add feedback loops for model updates.|


v8.0.0





71


​

​ ​


➔ ​ Publish model cards and limitations.


v8.0.0



72


​

​ ​

## **Program 8: Natural Language Processing (NLP)**

### Module 1: Introduction to NLP using Python and Word Representation

###### **Introduction**


This module grounds you in practical NLP using Python. You’ll clean and prepare text (tokenization,
stemming/lemmatization, POS tagging), then build core applications like Named Entity Recognition and
Sentiment Analysis while comparing rule-based and ML approaches. Next, you’ll learn why word
embeddings capture meaning, train/apply Word2Vec, and plug embeddings into downstream tasks. Finally,
you’ll evaluate models with accuracy/precision/recall/F1, run error analyses, tune with regularization and
data balancing, and document risks and bias. By the end, you’ll deliver robust, responsible NLP pipelines.

###### **Learning Objectives:**


By the end of this module,the learner will be able to :


➔ ​ Understand the fundamentals of Natural Language Processing (NLP) as a subfield of Artificial

Intelligence (AI) and its key applications in domains such as information retrieval, sentiment analysis,
machine translation, and question-answering.


➔ ​ Apply common NLP techniques like text preprocessing, tokenization, stemming, lemmatization,

part-of-speech tagging, and text classification algorithms.


➔ ​ Demonstrate proficiency in using popular NLP libraries such as NLTK, SpaCy, and TextBlob for basic

tasks.


➔ ​ Implement language modeling concepts, including n-grams, Markov models, and probabilistic

language models.


➔ ​ Utilize different text representation techniques such as Bag-of-Words (BoW), TF-IDF, and word

embeddings (Word2Vec, GloVe, FastText) to represent and extract features from text.


➔ ​ Evaluate the effectiveness of word representations, analyze challenges related to high-dimensional

and sparse word representations, and recognize the need for distributed, continuous word
embeddings.


➔ ​ Troubleshoot common NLP challenges and optimize models for efficiency while considering ethical

implications in NLP applications.


v8.0.0

73


​

​ ​



|Content|Col2|
|---|---|
|**Topic**<br>**Learning Outcomes**|**Topic**<br>**Learning Outcomes**|
|**Introduction to NLP**<br>**Concepts using**<br>**Python**|➔​ Explain core NLP goals, tasks, and common<br>challenges.<br>➔​ Identify Python NLP libraries (NLTK, others) and<br>their use cases.<br>➔​ Apply basic preprocessing: tokenization, stemming,<br>lemmatization, POS tagging.<br>➔​ Prepare raw text into clean, analysis-ready<br>datasets.|
|**NLP Applications and**<br>**Advanced Techniques**|➔​ Implement Named Entity Recognition and<br>Sentiment Analysis in Python.<br>➔​ Compare rule-based vs. statistical/ML approaches<br>for NLP tasks.<br>➔​ Diagnose common pitfalls in advanced NLP<br>(domain shift, ambiguity, data sparsity).<br>➔​ Evaluate application outputs and refne pipelines<br>based on errors.|
|**Word Embeddings**<br>**Representation**<br> <br>|➔​ Describe what word embeddings are and why they<br>capture semantics.<br>➔​ Compare embedding models (Word2Vec variants,<br>basics vs. contextual ideas).<br>➔​ Train/apply Word2Vec on sample text and interpret<br>similarity results.<br>➔​ Integrate embeddings into downstream tasks to<br>improve performance.analysis.|
|**Evaluating and**<br>**Optimizing NLP**<br>**Models**<br> <br>|➔​ Select and compute suitable metrics (accuracy, F1,<br>precision/recall).<br>➔​ Perform error analysis to guide model and data<br>improvements.<br>➔​ Apply basic optimization techniques (regularization,<br>tuning, data balancing).<br>➔​ Recognize ethical and bias considerations; document<br>limitations and risks|


v8.0.0































74


​

​ ​

### Module 2: Sequence Models

###### **Introduction**


In this module, you’ll learn how Recurrent Neural Networks model sequences, why they struggle with
long-term dependencies (vanishing gradients), and how LSTMs fix it with gated memory. We’ll unpack
hidden states, sequence propagation, and compare RNNs vs. feedforward nets. Then you’ll implement a
basic RNN and an LSTM for tasks like time series or text, evaluate their performance on long sequences, and
interpret how gates preserve information over time.

###### **Learning Objectives:**


By the end of this module, the learner will be able to :


➔ ​ Explain RNN structure, hidden states, and sequence propagation.


➔ ​ Analyze the vanishing gradient problem and its effects on learning.


➔ ​ Differentiate RNNs from feedforward networks for temporal data.


➔ ​ Implement a simple RNN to model short sequences.


➔ ​ Describe LSTM architecture (input/forget/output gates) and memory cell.


➔ ​ Build and evaluate an LSTM on sequence forecasting or text tasks.


➔ ​ Interpret gating dynamics to justify LSTM performance on long dependencies.



|Content|Col2|
|---|---|
|**Topic**<br>**Learning Outcomes**|**Topic**<br>**Learning Outcomes**|
|**RNN & Vanishing Gradient**<br>|➔​ Explain the concept and purpose of Recurrent<br>Neural Networks (RNNs) in sequential data<br>processing.<br>➔​ Describe the internal structure and operations<br>of RNNs, including hidden states and<br>sequence propagation.<br>➔​ Identify the vanishing gradient problem, its<br>causes, and its impact on long-term learning.<br>➔​ Implement a simple RNN in Python using a<br>deep learning framework to observe sequence<br>learning.<br>➔​ Compare RNNs with feedforward networks in<br>terms of data dependency and temporal|


v8.0.0













75


​

​ ​



|Col1|context.|
|---|---|
|**LSTM**<br>|➔​ Explain the motivation behind Long<br>Short-Term Memory (LSTM) networks as a<br>solution to vanishing gradients.<br>➔​ Describe the architecture of LSTMs, including<br>input, forget, and output gates.<br>➔​ Implement an LSTM model for sequence<br>prediction or time series tasks.<br>➔​ Compare LSTM performance against vanilla<br>RNNs on long sequence problems.<br>➔​ Interpret how LSTM’s gating mechanisms<br>retain long-term dependencies efectively.|


v8.0.0













76


​

​ ​

### Module 3: Foundations of Transformers and Sequence-to-Sequence Models in Machine Learning

###### **Introduction**


This module explains why transformers replaced RNN/CNNs for sequence modeling and how self-attention
captures long-range context efficiently. You’ll learn positional encoding, the encoder/decoder idea, and
where transformers shine in practice. Then we’ll dive into the mechanics: scaled dot-product attention,
multi-head attention, residual connections, layer normalization, and the feed-forward network inside a
transformer block. Finally, you’ll compare BERT (encoder, MLM/NSP) vs. GPT (decoder, autoregressive) and
choose suitable architectures for tasks like classification, QA, and generation.

###### **Learning Objectives:**


By the end of this module, the learner will be able to :


➔​ Explain why transformers outperform RNN/CNNs on long-context sequences.


➔​ Describe self-attention and justify the need for positional encoding.​


➔​ Compute scaled dot-product attention and interpret multi-head behavior.​


➔​ Decompose a transformer block (MHA → Add&Norm → FFN → Add&Norm).​


➔​ Analyze the roles of residual connections and layer normalization in stable training.​


➔​ Differentiate BERT vs. GPT objectives and architectures.​


➔​ Select an appropriate transformer variant for tasks (classification, QA, generation).

|Content|Col2|
|---|---|
|**Topic**<br>**Learning Outcomes**|**Topic**<br>**Learning Outcomes**|
|**Foundation of Transformers**|➔​ Explain why transformers were<br>introduced vs. RNN/CNN for sequences.<br>➔​ Describe the core idea of self-attention<br>and how it models context.<br>➔​ Explain positional encoding and why it’s<br>needed without recurrence.|



v8.0.0

77


​

​ ​



|Col1|➔​ Outline the high-level encoder/decoder<br>concept and data fol w.<br>➔​ Identify use cases where transformers<br>outperform earlier architectures.|
|---|---|
|**A Deep Dive Intro**<br>**Transformers**|➔​ Compute the intuition of scaled<br>dot-product and multi-head<br>self-attention.<br>➔​ Describe a transformer block: MHA→ <br>add & norm→ FFN→ add & norm.<br>➔​ Explain layer normalization and residual<br>connections for stable training.<br>➔​ Diferentiate BERT (encoder, MLM/NSP)<br>vs. GPT (decoder, autoregressive) and<br>their objectives.<br>➔​ Select suitable architectures (BERT vs.<br>GPT) for tasks like classifcation, QA, and<br>generation.|


v8.0.0













78


​

​ ​

## **Program 9: Generative AI Techniques**

### Module 1: Introduction to Generative AI and Text-based Techniques


**Introduction**


This module introduces Generative AI—what it is, how it evolved, and why it matters. You’ll contrast

generative vs. discriminative objectives, explore key applications (text, image, audio), and examine two

cornerstone families: Variational Auto-Encoders (VAEs) and Transformers. We unpack latent spaces and

sampling with VAEs, then cover encoder-only vs. decoder-only Transformer designs and how these underpin

diffusion models and LLMs. Throughout, we emphasize responsible use, ethics, and practical task-to-model

matching.


**Learning Objectives**


By the end of this module, learners will be able to:


➔ ​ Define Generative AI and major historical milestones.

➔ ​ Differentiate generative vs. discriminative models by objectives/outputs.

➔ ​ Describe VAE architecture and explain latent space roles.

➔ ​ Explain Transformer encoder-only vs. decoder-only designs and data flow.

➔ ​ Identify real-world applications across text, image, and audio.

➔ ​ Analyze trade-offs to select suitable models for given tasks.

➔ ​ Evaluate ethical implications and articulate responsible usage guidelines.


**Content**


**Topic** **Learning Outcomes**



**Introduction to**

**Generative AI**


v8.0.0



➔ ​ Explain the concept and evolution of Generative AI

and its historical milestones.

➔ ​ Differentiate between Generative and Discriminative

AI models in terms of objectives and outputs.

➔ ​ Identify key applications of Generative AI in text,

image, and audio generation.

➔ ​ Recognize ethical implications and responsible use of

Generative AI technologies.



79


​

​ ​



**Types of Generative**

**Models**


v8.0.0



➔​ Describe the architecture and working principle of

Variational Auto-Encoders (VAEs).


➔​ Explain the role of latent space representation in

generative modeling.


➔​ Identify practical applications of VAEs in image and

data synthesis.


➔​ Define the Transformer architecture and distinguish

between Encoder-only and Decoder-only models.


➔​ Connect VAEs and Transformers to broader

Generative AI frameworks like diffusion and large

language models (LLMs).



80


​

​ ​

### Module 2: Large Language Models (LLMs) and Prompts Engineering

###### **Introduction**


Build a practical, end-to-end understanding of LLMs. You’ll unpack the text-generation pipeline
(tokenization, embeddings, self-attention, positional encodings), implement a minimal Transformer block in
TensorFlow, and run training loops. Then you’ll generate text via API (e.g., Gemini) by tuning decoding
parameters, and fine-tune a base model (e.g., GPT-3.5 Turbo) to compare base vs. adapted behavior. Finally,
you’ll design evaluations (automatic + human), apply prompt-engineering techniques, and operationalize
Responsible AI guardrails for safe, reliable deployments.

###### **Learning Objectives:**


By the end of this module, the learner will be able to :


➔ ​ Explain LLM pipeline components and data flow.


➔ ​ Implement a minimal Transformer block and outline a training loop.


➔ ​ Generate outputs via API and tune decoding settings.


➔ ​ Fine-tune a model and compare base vs. fine-tuned results.


➔ ​ Design evaluation plans (metrics + human rubrics) and A/B tests.


➔ ​ Apply advanced prompting (role, few-shot, chain-of-thought) and iterate.


➔ ​ Evaluate risks and enforce Responsible AI guardrails (bias/toxicity monitoring, safety filters).



|Content|Col2|
|---|---|
|**Topic**<br>**Learning Outcomes**|**Topic**<br>**Learning Outcomes**|
|**A Deep Dive into Large**<br>**Language Models (LLMs)**|➔​ Explain the LLM text-generation pipeline and<br>core components (tokenization, embeddings,<br>self-attention, positional encodings).<br>➔​ Build a minimal Transformer block in<br>TensorFlow and outline the training loop<br>(data prep→ batching→ loss/optimizer→ <br>checkpoints).<br>➔​ Generate text with the Gemini API and tune<br>decoding settings (temperature, top-p, max<br>tokens) for quality vs. determinism.<br>➔​ Fine-tune GPT-3.5 Turbo on a small dataset|


v8.0.0





81


​

​ ​







|Col1|(formatting, validation, overfti ting checks) and<br>compare base vs. fni e-tuned outputs.<br>➔​ Describe LLM training paradigms (pretraining,<br>supervised fni e-tuning, RLHF) and trade-ofsf<br>in data, compute, and scaling.|
|---|---|
|**Large Language Models:**<br>**Applications & Evaluations**|➔​ Map common LLM applications (chatbots,<br>summarization, code, RAG, agents) to suitable<br>prompting/integration patterns.<br>➔​ Design evaluation plans using automatic<br>metrics (perplexity, ROUGE/BLEU,<br>exact-match, task scores) and task-specifc<br>checks.<br>➔​ Conduct structured human evals<br>(helpfulness, correctness, safety) with clear<br>rubrics and inter-rater consistency.<br>➔​ Monitor safety, bias, and toxicity; apply<br>guardrails (flters, instruction tuning, prompt<br>sanitization) and log incidents.<br>➔​ Iterate deployment with ofine tests and A/B<br>experiments; track drift and continuously<br>refne prompts/models.|
|**Prompts Engineering: Basics**<br>**& Advanced**|➔​ Explain the fundamentals of Prompt<br>Engineering and its role in controlling AI<br>model outputs.<br>➔​ Refne and structure prompts to achieve<br>optimal accuracy, creativity, or reasoning<br>depth.<br>➔​ Apply advanced techniques such as role<br>prompting, chain-of-thought, and few-shot<br>learning.<br>➔​ Experiment with prompt variations in<br>hands-on labs to observe diferences in<br>model behavior.<br>➔​ Evaluate prompt efectiveness and adjust<br>structure based on feedback and output<br>quality.|
|**Ethical and Efective AI**|➔​ Assess the efectiveness and impact of<br>prompts on model outputs and user<br>experience.|


v8.0.0



82


​

​ ​


➔ ​ Apply Responsible AI (RAI) principles when

designing and testing generative AI prompts.
➔ ​ Recognize and mitigate risks related to bias,

misinformation, and ethical misuse.
➔ ​ Establish clear guidelines for creating safe,

fair, and transparent AI-generated content.

### Module 4: Generative AI in Practice — Text, Image, & Audio

###### **Introduction**


This module is a hands-on tour of modern generative AI across text, image, and audio. We examine
representative systems—ChatGPT for text, Stable Diffusion for images, and Jukebox for music—to anchor
capabilities and limits. You’ll build intuition for diffusion via latent denoising, then generate images with
Stable Diffusion or Hugging Face tools. On the language side, you’ll craft controlled outputs with
temperature and decoding strategies and practice multi-turn dialogue design. You’ll explore text-to-speech
using Tacotron2 or VITS and produce short voice demos. We close with a Responsible AI lab on bias, misuse,
and IP risks, plus a discussion of watermarking and accountability.

###### **Learning Objectives:**


By the end of this module, the learner will be able to :


➔ ​ Compare generative examples for text, image, and music with clear strengths and limits.


➔ ​ Explain diffusion and latent denoising at a high level using intuitive analogies.


➔ ​ Operate image generation workflows with Stable Diffusion or Hugging Face pipelines.


➔ ​ Control text generation using temperature, top-k/p, and prompt engineering patterns.


➔ ​ Design multi-turn conversational flows that maintain context and constraints.


➔ ​ Build basic TTS pipelines with Tacotron2 or VITS and export short audio samples.


➔ ​ Assess RAI risks: bias, misuse vectors, safety filters, and IP exposure.


➔ ​ Discuss watermarking, transparency measures, and model accountability trade-offs.


➔ ​ Document experiments reproducibly, including prompts, seeds, configs, and outputs.
##### **Content**


**Topic** **Learning Outcomes**


v8.0.0

83


​

​ ​



|Understanding diffusion models and<br>latent denoising intuition|➔​ Explain forward noise addition and reverse<br>denoising steps conceptually.<br>➔​ Relate latents, schedulers, and guidance scale<br>to image quality.<br>➔​ Contrast pixel-space vs latent-space diffusion<br>trade-offs.<br>➔​ Connect classifier-free guidance to prompt<br>adherence.<br>➔​ Describe safety and compute implications of<br>sampling length.|
|---|---|
|**Generating images using**<br>**Stable Diffusion or Hugging**<br>**Face tools**|➔​ Confgure pipelines, models, and<br>VAE/tokenizer assets. <br>➔​ Tune sampler, steps, CFG scale, and<br>resolution. <br>➔​ Use prompt/negative-prompt patterns for style<br>and content control. <br>➔​ Apply seeds for reproducibility and batch<br>generation. <br>➔​ Export, tag, and curate outputs with metadata.|
|**Crafting text outputs with**<br>**controlled creativity and**<br>**temperature tuning**|➔​ Adjust temperature, top-k, and top-p to balance<br>coherence vs novelty. <br>➔​ Use system and user prompts to steer<br>persona and scope. <br>➔​ Apply content flters and guardrails for safe<br>outputs. <br>➔​ Evaluate outputs against task-specifc rubrics. <br>➔​ Create templates for consistent styles (e.g.,<br>summaries, emails, scripts).|
|**Generating multi-turn**<br>**dialogues and creative**<br>**stories**|➔​ Maintain narrative memory and character<br>consistency. <br>➔​ Design turn-taking and scene progression<br>constraints. <br>➔​ Inject controlled randomness for variation<br>without drift. <br>➔​ Track beats, arcs, and callbacks in outlines. <br>➔​ Record revision history and A/B alternative<br>branches.|


v8.0.0





84


​

​ ​



















|Exploring text-to-speech<br>with Tacotron2 or VITS|●​ Describe spectrogram synthesis and vocoder<br>roles simply.<br>●​ Load prebuilt checkpoints and match<br>preprocessing.<br>●​ Synthesize sentences with pace, pitch, and<br>pronunciation controls.<br>●​ Export WAV files at target sample rates.<br>●​ Log alignment issues and reduce artifacts.|
|---|---|
|**Producing short voice**<br>**synthesis demos**|●​ Storyboard demo scripts and consent<br>requirements. <br>●​ Batch render clips and normalize loudness. <br>●​ Package demos with captions and usage<br>notes. <br>●​ Add disclaimers on synthetic media and<br>limitations. <br>●​ Collect feedback and iterate on clarity and<br>tone.|
|**Conducting Responsible AI**<br>**lab: bias, misuse, and IP risk**<br>**assessment**|●​ Identify sensitive prompts and potential<br>misuse scenarios. <br>●​ Run bias and toxicity probes; document<br>fndings. <br>●​ Assess copyright/IP risks and implement<br>fltering/attribution practices. <br>●​ Defne escalation paths and red-team<br>checklists. <br>●​ Propose mitigations and user-facing<br>transparency statements.|


v8.0.0













85


​

​ ​

## **Program 10: Introduction to Agentic AI Development**
### Module 1: Foundations of Agentic AI

##### **Introduction**


This module explores the theory and architecture behind Agentic AI — intelligent systems capable of

autonomous reasoning, planning, and action. Learners will examine the evolution from traditional software

to agent-based designs, comparing reactive, deliberative, and hybrid decision models. The module then

dissects agent architectures, memory systems, and dynamic adaptation via feedback loops. Finally, learners

will explore memory-augmented systems like Retrieval-Augmented Generation (RAG), understanding how

agents integrate knowledge retrieval to make context-aware, scalable decisions across real-world

applications.

##### **Learning Objectives:**


By the end of this module, the learner will be able to:

➔​ Define core traits and structures that distinguish Agentic AI from traditional applications.


➔​ Compare agent types and analyze decision-making strategies (reactive, deliberative, hybrid).


➔​ Describe the architecture and components (controller, planner, executor, memory) of agentic

systems.


➔​ Illustrate information flow and evaluate how feedback and memory enhance adaptability.


➔​ Differentiate memory types (short-term, vector, episodic) and their conceptual roles.


➔​ Explain the RAG framework and analyze its advantages in memory-augmented agents.


➔​ Design a conceptual model of a dynamic, memory-enhanced agent and propose strategies for

scalable, adaptive deployment.


v8.0.0

86


​

​ ​

##### **Content**


**Topic** **Learning Outcomes**



**Agentic AI**
**Fundamentals**


**Agent Types & Decision**
**Strategies**


v8.0.0



➔ ​ Define the essential characteristics that distinguish



agents from traditional applications, focusing on
autonomy, perception, and the action loop.
➔ ​ Describe the internal structure of an agent, outlining



the flow from input through reasoning/planning to
output.
➔ ​ Compare agentic AI with traditional software



approaches, highlighting differences in flexibility,
adaptability, and feedback utilization.
➔ ​ List and explain the core traits that characterize



intelligent agents, such as goal orientation,
adaptability, and self-evaluation.
➔ ​ Summarize how an agent’s reasoning and planning



enable dynamic responses to changing
environments.
➔ ​ Illustrate the concept of a simple agent, using



schematic diagrams to show information flow.
➔ ​ Evaluate the theoretical advantages of agentic AI in



scenarios requiring autonomy and learning.



➔ ​ Identify and classify the main types of agents:

reactive, deliberative, and hybrid.
➔ ​ Compare the strengths and limitations of reactive



and deliberative decision strategies.
➔ ​ Describe how reactive agents rely on heuristics and

rules to respond quickly, and recognize the limits of
such approaches.
➔ ​ Explain the deliberative agent’s use of planning,

memory look-ups, and reasoning cycles for complex
decisions.
➔ ​ Analyze the benefits of hybrid agent strategies that



combine multiple decision-making models.
➔ ​ Determine how to select an appropriate agent type



and strategy based on specific task requirements and
environmental contexts.
➔ ​ Develop mental models to distinguish and choose



between different agent architectures in theoretical
scenarios.



87


​

​ ​



**Architecture, Components &**
**Tooling**


**Dynamic Agents: Feedback,**
**Memory & Knowledge**


**Memory-Enhanced Systems:**
**RAG & Production**


v8.0.0



➔ ​ Describe the key architectural components of agentic

AI systems, including controller, planner, and
executor roles.
➔ ​ Explain the importance of modular design in enabling



flexibility and scalability in agent systems.
➔ ​ Distinguish between different integration patterns



used for connecting agent components and
managing workflows.
➔ ​ Classify types of memory storage (short-term,



long-term, vector-based) and explain their conceptual
roles in agent systems.
➔ ​ Illustrate the flow of information and



decision-making within an agent architecture using
block diagrams.
➔ ​ Evaluate the theoretical benefits and challenges of

integrating memory components within agentic
systems.
➔ ​ Summarize best practices in designing agent

architectures to support reasoning and adaptability.



➔ ​ Compare static and dynamic agent models,



emphasizing the role of feedback in adaptation.
➔ ​ Describe how feedback loops contribute to



continuous learning and improvement in agentic
behavior.
➔ ​ Explain the different types of memory in agents



(buffer, episodic, vector), and how each supports
reasoning and context.
➔ ​ Summarize the process of knowledge retrieval and

contextual filtering in agentic systems.
➔ ​ Evaluate the effectiveness of human-in-the-loop

interventions for improving agent performance.
➔ ​ Analyze theoretical workflows where feedback and

memory enable agents to adapt to novel or
ambiguous situations.
➔ ​ Design a conceptual model of a dynamic agent,

showing how memory and feedback enhance
adaptability.


➔ ​ Define retrieval-augmented generation (RAG) as an

architectural paradigm that combines generation
with memory retrieval.



88


​

​ ​


➔ ​ Describe the conceptual stages of a RAG pipeline:

ingesting data, indexing, retrieving relevant
knowledge, generating responses, and evaluating
outputs.
➔ ​ Analyze real-world scenarios where

memory-augmented agents outperform traditional
approaches.
➔ ​ Explain the value of integrating memory retrieval into



agentic workflows for tasks like support chatbots.
➔ ​ Evaluate different strategies for scaling



memory-augmented systems, considering factors like
latency and evaluation metrics.
➔ ​ Summarize the theoretical process of deploying



memory-enhanced agents and monitoring their
performance in operational settings.
➔ ​ Propose ways in which memory-enhanced agentic AI



can be adapted for future, evolving use cases.



v8.0.0



89


​

​ ​

### Module 2: Introduction to Dify AI Agentic Framework

##### **Introduction**


This module introduces learners to **Dify AI**, a zero-code platform for designing, deploying, and scaling

intelligent agents. It covers the full lifecycle—from understanding Dify’s architecture and dashboard, to

crafting domain-specific agents with role-goal-tool schemas, memory integration, and retrieval-augmented

knowledge. Learners will explore how feedback loops and human-in-the-loop systems improve reliability,

and how to manage production-scale rollouts with observability, versioning, and secure deployment. By the

end, learners will be able to prototype, refine, and operationalize agents confidently within the Dify AI

ecosystem.

##### **Learning Objectives:**


By the end of this module, the learner will be able to:

➔​ **Describe** the mission, workflow, and core features of Dify AI for agent development.


➔​ **Design** domain-specific agents using prompt strategies, role-goal-tool schemas, and skill chains.​


➔​ **Integrate** memory and retrieval mechanisms (short-term, long-term, RAG) to enhance agent

performance.


➔​ **Implement** dynamic feedback loops and **apply** human-in-the-loop techniques for quality assurance.​


➔​ **Evaluate** agent autonomy levels and design reviewer checkpoints for safe decision-making.​


➔​ **Analyze** production-scale practices—versioning, observability, and deployment strategies.​


➔​ **Demonstrate** an end-to-end Dify AI agent lifecycle from prototype to monitored production rollout.


v8.0.0

90


​

​ ​

##### **Content**


**Topic** **Learning Outcomes**



**Dify AI Kick-off**


**Designing**
**Domain-Specific**
**Agents**


**Memory & Knowledge**
**in Dify**


v8.0.0



➔ ​ Describe the mission and unique value proposition of

Dify AI in the agent development ecosystem.
➔ ​ Summarize the main features and layout of the Dify

AI dashboard for agent lifecycle management.
➔ ​ Explain how to connect various data sources to Dify,

highlighting the importance of zero-code
configuration.
➔ ​ Define the role, goal, and tool schema used for agent

design within Dify AI.
➔ ​ Outline the typical workflow for building and testing a

basic support bot.
➔ ​ Identify the steps for deploying an agent from the

dashboard, from initial creation to testing.
➔ ​ Evaluate the advantages of using Dify AI for rapid

prototyping and deployment of conversational
agents.


➔ ​ Explain how to scope agent personas and tasks for

domain-specific accuracy.
➔ ​ Apply prompt engineering strategies within Dify to

guide agent responses and ensure reliable outputs.
➔ ​ Describe the use of skill chains and when agents

should trigger actions or call external functions.
➔ ​ Distinguish between reactive and planning-based

decision strategies and relate them to agent
archetypes.
➔ ​ Design step-by-step planning workflows for agents to



decompose complex goals into tasks.
➔ ​ Analyze domain needs to create customized agent



templates using the role, goal, and tool schema.
➔ ​ Evaluate different strategies for improving agent



specialization and performance within targeted
domains.



➔ ​ Describe the role of short-term memory buffers in

maintaining conversational context.
➔ ​ Explain how long-term vector memory supports

persistent knowledge within agents.
➔ ​ Summarize the process for auto-indexing documents



91


​

​ ​


and PDFs to enhance agent knowledge.
➔ ​ Outline the principles of retrieval-augmented

generation (RAG) as applied in Dify AI.
➔ ​ Analyze how integrating memory and retrieval



features impacts the quality and relevance of agent
outputs.
➔ ​ Evaluate the benefits of memory-powered agents in



handling FAQ and support scenarios.
➔ ​ Demonstrate methods for monitoring and improving



memory utilization in agent workflows.



**Dynamic Behavior &**
**Human-in-Loop**



➔ ​ Explain how feedback loops drive continuous

improvement in agent decision-making.
➔ ​ Describe the use of quality gates and evaluation

metrics to assess agent responses.
➔ ​ Illustrate the human-in-the-loop (HITL) override

process for ensuring agent reliability and safety.
➔ ​ Differentiate between levels of agent autonomy and

settings for progressive adjustment.
➔ ​ Summarize workflows where agents pause for



human review before continuing operations.
➔ ​ Evaluate the impact of HITL integration on agent



performance and accountability.
➔ ​ Design procedures for implementing reviewer



checkpoints in live agent deployments.



**Production & Scale** ➔ ​ Explain the importance of versioning and rollback



mechanisms for safe agent deployment.
➔ ​ Describe tactics for controlling operational costs,



such as model tiering and batching.
➔ ​ Summarize how observability dashboards provide



visibility into agent health and errors.
➔ ​ Outline key considerations for maintaining security



and compliance in agent workflows.
➔ ​ Analyze best practices for monitoring agent



deployments at scale.
➔ ​ Evaluate the effectiveness of blue/green deployment



strategies for minimizing downtime.
➔ ​ Demonstrate a complete production launch cycle,

from model release to real-time monitoring and
traffic switching.



v8.0.0



92


​

​ ​

### Module 3: Introduction to n8n Agentic Framework


**Introduction**


In this practical, hands-on series, you'll learn how to harness n8n’s automation power to design, run, and

monitor robust AI workflows. We’ll start with the basics of n8n, plug in AI agents, work with memory and

retrieval, and finish with dynamic human-in-the-loop processes and scaling best practices. Whether you’re

automating solo or building for a team, this module is your guide to creating smart, flexible, and scalable

AI-powered flows with n8n.


**Learning Outcomes**


By the end of this module, learners will be able to:


➔ ​ Understand n8n’s capabilities for building flexible, event-driven automations.

➔ ​ Deploy n8n on local and cloud infrastructure.

➔ ​ Automate AI-driven workflows using agent integration and secure data handling.

➔ ​ Enable memory and retrieval in automations using databases and vector DBs.

➔ ​ Implement human-in-the-loop steps and dynamic flow branching for quality and compliance.

➔ ​ Monitor, scale, and troubleshoot complex automations reliably.

➔ ​ Manage cost and performance for sustainable, production-ready AI workflow automation.


**Content**


**Topic** **Learning Outcomes**



**n8n fundamentals**


v8.0.0



➔ ​ Explain the main features and value of n8n for

automating AI workflows.

➔ ​ Describe how nodes, triggers, and credentials form the

core structure of n8n flows.

➔ ​ Install and configure n8n both locally and in the cloud for

various use cases.

➔ ​ Navigate and secure the n8n dashboard and its core

components.

➔ ​ Apply best practices in naming, organizing, and

documenting automation flows.

➔ ​ Integrate error handling and troubleshooting strategies

into simple workflows.

➔ ​ Build, test, and reflect on an end-to-end automation

project using n8n.



93


​

​ ​



**Plugging AI Agents**

**into n8n**


**Memory, Storage &**

**RAG in n8n**


**Dynamic &**

**Human-in-Loop**

**Workflows**


v8.0.0



➔ ​ Configure HTTP nodes to connect n8n workflows with

external AI endpoints and services.

➔ ​ Securely store, manage, and use API keys and

authentication tokens using n8n’s credentials system.

➔ ​ Extract and parse agent responses (JSON) to capture

relevant data for workflow use.

➔ ​ Map and transform agent outputs into variables for

routing and downstream actions.

➔ ​ Implement conditional logic to route data and automate

decisions based on agent results.

➔ ​ Design, build, and optimize workflows that coordinate

multiple AI agents, either sequentially or in parallel.

➔ ​ Test, troubleshoot, and validate multi-agent

workflows—ensuring smooth data flow and reliable,

real-world automation.


➔ ​ Connect and configure n8n with external databases

(Postgres, Mongo, Airtable) for data storage.

➔ ​ Store and retrieve workflow data to enable persistent

memory and automation state.

➔ ​ Integrate vector databases (e.g., Pinecone, Qdrant) for

embedding storage and similarity search.

➔ ​ Build Retrieval-Augmented Generation (RAG) sub-flows

that combine embedding, searching, and answering.

➔ ​ Implement caching strategies and set time-to-live (TTL) to

optimize latency and reduce API costs.

➔ ​ Monitor, structure, and validate data interactions within

memory and storage flows.

➔ ​ Demonstrate real-time information retrieval using RAG

with live lookup demos.


➔ ​ Design workflows that incorporate human-in-the-loop

steps, such as pauses for approvals or manual input.

➔ ​ Set up webhooks to trigger, pause, or resume

automations based on external events.

➔ ​ Route outputs dynamically by branching on quality

scores and feedback.



94


​

​ ​


➔ ​ Build interactive forms and dashboards for collecting

additional user input during workflows.

➔ ​ Log workflow actions, maintain audit trails, and support

compliance through effective logging.

➔ ​ Track, manage, and escalate tasks that require human

review for improved workflow quality.

➔ ​ Optimize workflow reliability and transparency by

combining automation with human oversight.



**Scaling, Monitoring &**

**Cost**


v8.0.0



➔ ​ Enable and manage queues and concurrency settings to

scale workflow execution.

➔ ​ Integrate external queueing systems (RabbitMQ, Redis)

for high-volume task processing.

➔ ​ Implement robust error handling patterns, including

retries and dead-letter handling.

➔ ​ Monitor workflow health and performance using

observability tools like Prometheus and Grafana.

➔ ​ Apply budget guardrails—set usage caps, resource limits,

and alerting to control costs.

➔ ​ Stress test workflows and analyze auto-scaling to ensure

reliable performance under load.

➔ ​ Optimize workflow efficiency and cost-effectiveness

through monitoring, alerts, and resource management.



95


​

​ ​

### Module 4: LangChain — Foundations & Applications


**Introduction**


Start from first principles and build a mental model of LangChain as a composable framework for LLM apps.

You’ll understand its core abstractions (prompts, models, parsers, tools, memory, chains) and see how

prompt templates, schema validation, and output enforcement create reliable behavior. Then you’ll move

from concepts to practice by assembling workflows with sequential, router, and parallel chains. By the end,

you’ll be able to prototype end-to-end chatbot flows in a handful of lines, enforce structured JSON outputs,

and select the right chain type to balance control, performance, and maintainability.


**Learning Outcomes**


By the end of this module, learners will be able to:


➔ ​ Explain LangChain’s core building blocks and how they interact.

➔ ​ Create robust prompt templates and avoid hard-coding.

➔ ​ Enforce structured JSON with data models and validators.

➔ ​ Apply output enforcement to keep models within rules.

➔ ​ Design sequential, router, and parallel chains for real tasks.

➔ ​ Prototype chatbot flows rapidly with minimal glue code.

➔ ​ Document assumptions and evaluate chain choices trade-offs.

|Content|Col2|
|---|---|
|**Topic**<br>**Learning Outcomes**|**Topic**<br>**Learning Outcomes**|
|**Foundations of LangChain**|➔​ Describe key abstractions: prompt templates, LLMs,<br>parsers, memory, tools, chains.<br>➔​ Build prompt templates to parameterize inputs and<br>reduce duplication.<br>➔​ Model outputs with schemas to get structured JSON<br>reliably.<br>➔​ Apply output enforcement to constrain style, format,<br>and content.<br>➔​ Prototype a basic chatbot fow and summarize design<br>decisions.|
|**Chaining & Chain Flows**|➔​ Choose among sequential, router, and parallel chains<br>based on routing needs.|



v8.0.0

96


​

​ ​


**in LangChain** ➔ ​ Compose steps with shared context and safe

fallbacks.
➔ ​ Instrument chains for observability and simple

debugging.
➔ ​ Integrate validation/parsing at chain boundaries.
➔ ​ Refactor a monolithic flow into maintainable chain

components.

### Module 5: Tools & Memories in LangChain


**Introduction**


Go deeper with state and external capabilities. You’ll compare memory types—from simple buffers and

windows to summarization and vector-store retrieval—and align them to conversation length and cost

constraints. Then you’ll extend your chains with tools: code execution, search, HTTP requests, SQL,

Wikipedia, and vector-store QA. You’ll learn safe tool invocation patterns, latency budgeting, and how to

keep outputs structured when tools are in the loop. The result is conversational apps that remember what

matters and can act on the world when needed.


**Learning Outcomes**


By the end of this module, learners will be able to:


➔ ​ Differentiate memory types and select the right one per use case.

➔ ​ Configure ConversationBuffer, Window, Summary, and VectorStore memories.

➔ ​ Integrate external tools to augment model capabilities safely.

➔ ​ Design tool-aware chains with guardrails and timeouts.

➔ ​ Measure cost/latency impacts of memory and tools.

➔ ​ Maintain structured outputs even with tool calls in the loop.

|Content|Col2|
|---|---|
|**Topic**<br>**Learning Outcomes**|**Topic**<br>**Learning Outcomes**|
|**Memories in LangChain**|➔​ Contrast buffer, windowed, summary, and vector-store<br>memories.<br>➔​ Implement ConversationBuffer/Window/Summary for<br>different dialog lengths.|



v8.0.0

97


​

​ ​



|Col1|➔​ Use VectorStoreRetrieverMemory for semantic recall.<br>➔​ Control memory growth, truncation, and privacy<br>considerations.<br>➔​ Evaluate memory effectiveness with targeted test<br>dialogs.|
|---|---|
|**Extending Chains with**<br>**External Tools**|●​ Integrate Python REPL, SerpAPI, GET requests,<br>Wikipedia, SQL, and VectorStore QA. <br>●​ Design tool selection prompts and failure fallbacks. <br>●​ Budget latency and rate limits; add retries and<br>timeouts. <br>●​ Validate and sanitize tool inputs/outputs for safety. <br>●​ Log tool usage and outcomes for debugging and<br>evaluation.|


v8.0.0





98


​

​ ​

### Module 6: LangChain — Tools, Agents & RAG


**Introduction**


Move from fixed chains to adaptive reasoning and knowledge grounding. You’ll understand agent patterns

and popular flavors (ReAct, self-query, multi-agent coordination), then build a basic agent that chooses tools

and reasons step-by-step. Next, you’ll implement Retrieval-Augmented Generation end-to-end: ingestion

and chunking, embeddings, vector store selection, retrieval strategies, generation, and

evaluation/monitoring. You’ll leave with practical blueprints for agents that can plan and act, and RAG

systems that are inspectable, testable, and production-ready.


**Learning Outcomes**


By the end of this module, learners will be able to:


➔ ​ Explain agent concepts and compare common agent flavors.

➔ ​ Build a working ReAct agent with safe tool use.

➔ ​ Coordinate multiple agents for decomposition or oversight.

➔ ​ Implement RAG: loaders, chunking, embeddings, vector stores, retrievers.

➔ ​ Assemble generation pipelines with grounded, structured outputs.

➔ ​ Monitor, debug, and evaluate agent and RAG performance.



|Content|Col2|
|---|---|
|**Topic**<br>**Learning Outcomes**|**Topic**<br>**Learning Outcomes**|
|**Building your own Agent**|➔​ Differentiate agents vs chains and when to prefer<br>each.<br>➔​ Implement a basic tool-using agent with clear<br>reasoning traces.<br>➔​ Build a ReAct agent and analyze<br>thought/action/observation loops.<br>➔​ Apply self-query and retrieval-aware planning.<br>➔​ Design multi-agent coordination patterns and guard<br>against loops.|
|**Knowledge Integration**<br>**& Retrieval**|➔​ Ingest documents with loaders; chunk with overlap<br>and heuristics.<br>➔​ Generate embeddings and choose models ft for<br>domain/latency.|


v8.0.0





99


​

​ ​


➔ ​ Select and configure vector stores (e.g., Chroma) and

retrievers.
➔ ​ Build generation pipelines with citation and answer

validation.
➔ ​ Monitor, debug, and evaluate RAG quality with targeted

probes.


v8.0.0



100


​

​ ​

## **Program 11: Career Boost**

### Module 1: C.V. writing


**Introduction**


Build a clean, targeted CV that recruiters can scan in seconds. You’ll learn when to use a CV vs. résumé, the
must-have sections (contact, objective, education, experience, internships, projects, courses, skills), and how
formatting boosts readability. We’ll practice writing impact-first bullets, tailoring objectives to roles, selecting
relevant projects/courses, and presenting skills honestly. You’ll also learn when and how to add optional
sections (languages, awards, volunteering) to strengthen your profile.


**Learning Objectives**


By the end of this module, learners will be able to:

➔ ​ Differentiate CV vs. résumé and select the right format.
➔ ​ Organize a professional CV using clear, consistent structure.
➔ ​ Compose tailored job objectives aligned to specific roles.
➔ ​ Craft impact-driven experience bullets with action verbs and metrics.
➔ ​ Select and present relevant projects, courses, and internships effectively
➔ ​ Categorize and report skills with honest proficiency levels
➔ ​ Evaluate optional sections and refine formatting for readability and first impressions.

##### **Content**


**Topics** **Learning Outcomes**



**Introduction** ➔ ​ Explain the difference between a **CV** and a **Resume**



and when to use each.
➔ ​ Identify the **purpose and goals** of a professional CV.
➔ ​ Outline the main **sections and structure** of an



effective CV.
➔ ​ Recognize how clear formatting and organization



enhance readability.
➔ ​ Prepare to apply this structure in later assessments



and exercises.



**Contact Info** ➔ ​ Identify key contact information to include (name,

phone, email, address).


➔ ​ Apply professional standards for email, LinkedIn, and



v8.0.0



101


​

​ ​


GitHub presentation.


➔ ​


➔ ​ Ensure consistency and accuracy across contact

channels.


➔ ​ Recognize how small details (URLs, naming,

formatting) affect first impressions.



**Job Objective** ➔ ​ Define the purpose of a job objective and its role in a

CV.
➔ ​ Write clear and tailored objectives aligned with

specific job roles.
➔ ​ Follow step-by-step methods to craft impactful



objective statements.
➔ ​ Differentiate between generic and customized job

objectives using examples.



**Education** ➔​ Identify which education details are relevant for your

career stage.


➔​ Format education entries consistently and clearly.


➔​ Highlight key achievements, GPA, or coursework

when appropriate.


➔​ Use examples to understand effective presentation

of educational background.


**Work Experience** ➔ ​ Describe how to structure and present professional

experience effectively.
➔ ​ Use action verbs and quantifiable results to

strengthen entries.
➔ ​ Apply a clear step-by-step format (role → company

→ achievements).
➔ ​ Distinguish between job responsibilities and

impact-driven bullet points.



**Internships** ➔ ​ Explain the importance of including internships in



early-career CVs.
➔ ​ Describe how to present internship experiences with



clarity and relevance.
➔ ​ Highlight key skills or achievements gained from



v8.0.0



102


​

​ ​



**Extra Curricular**
**Activities**



internships.
➔ ​ Write internship descriptions that demonstrate

readiness for full-time roles


➔ ​ Define what counts as an extra-curricular activity for

professional CVs.
➔ ​ Identify how to frame activities to show transferable

skills (leadership, teamwork, creativity).
➔ ​ Apply concise and relevant wording when listing



activities.
➔ ​ Recognize how this section adds personality and

differentiates your profile.


**Project** ➔ ​ Explain the importance of showcasing academic or



professional projects in a CV.
➔ ​ Identify which projects best demonstrate relevant skills



for the target role.
➔ ​ Structure project entries with clear objectives, tools



used, and outcomes.
➔ ​ Quantify project results where possible (e.g., accuracy



improved by 15%).
➔ ​ Apply consistent formatting and language that highlight



your problem-solving impact.



**Courses** ➔ ​ Recognize how listing courses and certifications



supports your professional credibility.
➔ ​ Select courses relevant to your industry or desired job



path.
➔ ​ Format each course entry clearly with title,



platform/institution, and completion date.
➔ ​ Differentiate between short courses, diplomas, and



verified certifications.
➔ ​ Ensure alignment between listed courses and stated

career objectives.


**Skills** ➔ ​ Identify technical, analytical, and soft skills relevant to

the target role.
➔ ​ Group skills into categories (e.g., Programming, Tools,

Communication).
➔ ​ Demonstrate skill proficiency honestly and clearly (e.g.,

beginner/intermediate/advanced).
➔ ​ Prioritize in-demand skills that match job requirements.


v8.0.0



103


​

​ ​


➔ ​ Maintain visual balance — concise, easy-to-scan skill

sections


**Optional Sections** ➔ ​ Recognize how this section adds personality and

differentiates your profile.


**Tips & Tricks** ➔ ​ Recognize which optional sections add value depending

on experience level.
➔ ​ Present languages, awards, or volunteering clearly and

concisely.
➔ ​ Include references professionally when relevant or

requested.
➔ ​ Use optional sections strategically to strengthen your

profile’s depth.
➔ ​ Maintain focus — include only sections that enhance

your candidacy.


v8.0.0



104


​

​ ​

### Module 2: Understanding Interviews


**Introduction**


This module helps learners understand the interview process from both the employer’s and applicant’s
perspectives. It explains what hiring managers look for, the different interview types, and how to adapt
effectively to each format. Learners will also explore how mindset influences performance—developing
confidence, calmness, and self-awareness. By the end, participants will know how to approach interviews
strategically, communicate authentically, and align their responses with employer expectations.


**Learning Objectives**


By the end of this module, learners will be able to:

➔ ​ Describe the purpose and flow of the job interview process
➔ ​ Identify key traits and competencies employers seek in candidates.
➔ ​ Differentiate among interview types (phone, panel, group, online, face-to-face).
➔ ​ Apply appropriate strategies for each interview format.
➔ ​ Explain how mindset and self-awareness influence communication.
➔ ​ Develop techniques for confidence, calmness, and adaptability under pressure.
➔ ​ Analyze employer expectations and align responses to demonstrate fit and readiness.

##### **Content**


**Topics** **Learning Outcomes**



**What Employers Want** ➔ ​ Define the main purpose and structure of job



interviews.
➔ ​ Describe the overall hiring process from application



to offer.
➔ ​ Explain what HR professionals look for in candidates.
➔ ​ Analyze how applicants can align their responses



with employer expectations.


**Types of Interviews** ➔ ​ Identify different interview types: phone, online,

panel, group, and face-to-face.
➔ ​ Explain the unique goals and characteristics of each



interview format.
➔ ​ Prepare strategies to perform effectively in diverse



interview settings.
➔ ​ Recognize how assessment centers evaluate



collaboration and problem-solving skills.



**Interview Mindset** ➔ ​ Explain how mindset influences performance and


v8.0.0



105


​

​ ​


first impressions.
➔ ​ Differentiate between confidence and desperation in

communication.
➔ ​ Apply growth mindset principles to handle feedback

and challenges.
➔ ​ Build mental preparation techniques for staying calm

and authentic.


v8.0.0



106


​

​ ​

### Module 3: Pre-Interview Preparations


**Introduction**


This module equips learners with the strategies and tools needed to prepare confidently for interviews. It
covers targeted company and role research, personal readiness, and the use of AI-powered tools for
practice. Learners will learn how to align their skills with job requirements, structure behavioral responses
using the STAR method, and present themselves professionally. By blending traditional preparation with
modern AI feedback, learners will develop the self-awareness and confidence to perform effectively in real
interviews.


**Learning Objectives**


By the end of this module, learners will be able to:

➔ ​ Research company mission, culture, and interviewer background.
➔ ​ Analyze job descriptions to match personal skills and experiences.
➔ ​ Formulate insightful questions that demonstrate genuine interest.
➔ ​ Apply the STAR method to craft structured, behavioral responses.
➔ ​ Demonstrate professionalism through appropriate attire and soft-skill readiness.
➔ ​ Simulate interviews using AI tools and evaluate feedback analytics.
➔ ​ Refine communication tone and delivery based on AI-driven performance insights.

##### **Content**


**Topics** **Learning Outcomes**


**Research** ➔ ​ Conduct targeted research on the company’s

mission, values, and culture.
➔ ​ Investigate interviewer background and interview

panel structure.
➔ ​ Analyze job descriptions to match required skills and

experiences.
➔ ​ Prepare questions that show knowledge and genuine

interest in the company


**Personal Preparation** ➔ ​ Identify and strengthen personal soft skills relevant



to the interview.
➔ ​ Recall professional experiences to use as strong



interview examples.
➔ ​ Apply the STAR method to answer behavioral



questions effectively.
➔ ​ Choose appropriate attire that reflects



professionalism and company culture.



v8.0.0



107


​

​ ​


**AI Tools** ➔ ​ Use AI-based tools to simulate interview

environments.
➔ ​ Evaluate answers to situational and behavioral

questions using feedback analytics.
➔ ​ Identify areas for improvement in communication

and delivery.
➔ ​ Adjust tone and structure of answers based on AI

evaluation insights.


v8.0.0



108


​

​ ​


v8.0.0



109


​

​ ​

### Module 4: During & Post Interview


**Introduction**


This module prepares learners to perform confidently and professionally during and after interviews. It
focuses on effective communication behaviors, structured answering techniques, and post-interview
etiquette. Learners will master body language, active listening, and the STAR method to tackle behavioral
and situational questions. They’ll also practice responding to common interview questions and managing
challenging moments with composure. Finally, learners will reflect on their performance, craft impactful
follow-ups, and build habits for continuous improvement.


**Learning Objectives**


By the end of this module, learners will be able to:


➔​ Demonstrate professional body language and active listening behaviors.
➔​ Apply structured methods (like STAR) to answer diverse question types.
➔​ Recognize interviewer intent and respond with clarity and confidence.
➔​ Compose strong responses to common interview questions.
➔​ Discuss career motivations, strengths, and salary expectations professionally.
➔​ Evaluate interview performance using reflection and feedback.
➔​ Develop follow-up communication that reinforces professionalism and interest.

##### **Content**


**Topics** **Learning Outcomes**



**Behaviours** ➔ ​ Maintain positive body language, posture, and facial

expressions.
➔ ​ Use consistent eye contact to establish trust and

attentiveness.
➔ ​ Demonstrate active listening through verbal and

non-verbal cues.
➔ ​ Avoid distracting habits or gestures that may reduce

credibility.


**Types of Questions** ➔ ​ Differentiate between behavioral, situational, and

stress questions.
➔ ​ Apply structured methods (e.g., STAR) to respond



effectively.
➔ ​ Recognize the interviewer’s intent behind each



question type.
➔ ​ Manage unexpected or challenging questions with



composure.



v8.0.0



110


​

​ ​



**Most Common**
**Questions & Answers**



➔ ​ Formulate strong responses to typical questions (e.g.,

“Tell me about yourself”).
➔ ​ Present career motivations and achievements



confidently.
➔ ​ Identify and express strengths and weaknesses with



honesty and professionalism.
➔ ​ Discuss salary expectations tactfully and strategically.
➔ ​ Participate in a use-case interview to apply learned



techniques.



**Post-Interview** ➔ ​ Prepare thoughtful questions to ask the interviewer



after the session.
➔ ​ Reflect on performance using structured evaluation



criteria.
➔ ​ Send effective follow-up messages to reinforce



interest and professionalism.
➔ ​ Maintain a personal interview checklist for



continuous improvement.



v8.0.0



111


